<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://sanjanad1024.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sanjanad1024.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-06-06T01:00:02+00:00</updated><id>https://sanjanad1024.github.io/feed.xml</id><title type="html">blank</title><subtitle>Personal page of Sanjana Das. </subtitle><entry><title type="html">An Interactive Proof for Count-SAT</title><link href="https://sanjanad1024.github.io/blog/2024/ip-countsat/" rel="alternate" type="text/html" title="An Interactive Proof for Count-SAT"/><published>2024-06-04T00:00:00+00:00</published><updated>2024-06-04T00:00:00+00:00</updated><id>https://sanjanad1024.github.io/blog/2024/ip-countsat</id><content type="html" xml:base="https://sanjanad1024.github.io/blog/2024/ip-countsat/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>In the <a href="https://sanjanad1024.github.io/blog/2024/interactive-proofs/" target="_blank">previous post</a> on interactive proofs, we defined $\textsf{IP}$ as the class of decision problems which can be solved using an interactive proof with a computationally unbounded prover and computationally bounded, <em>randomized</em> verifier — meaning that there’s an efficient verifier such that for each $\textsf{YES}$ instance there <em>exists</em> a ‘good prover’ that makes the verifier accept with high probability, while for each $\textsf{NO}$ instance the verifier rejects <em>every</em> ‘cheating prover’ with high probability. (We refer to these two statements as <span class="vocab">completeness</span> and <span class="vocab">soundness</span>, respectively.)</p> <div class="question"> How powerful are interactive proofs &mdash; what sorts of problems are in $\textsf{IP}$? </div> <p>In the previous post, we saw that $\textsf{NP} \subseteq \textsf{IP}$. We don’t even need interaction (or randomness) for this — we can just have the prover send over the $\textsf{NP}$-certificate, and the verifier check that it works. For example, there’s a very simple protocol for $\textsf{SAT}$ (where the prover wants to convince the verifier that a Boolean formula is satisfiable) — the prover just sends over a satisfying assignment, and the verifier plugs it in.</p> <p>But it turns out that $\textsf{IP}$ is much more powerful than this — there’s tons of problems that we don’t expect to be in $\textsf{NP}$, but which nevertheless have interactive proofs.</p> <div class="theorem" text="Shamir 1990"> We have $\textsf{IP} = \textsf{PSPACE}$. </div> <p>In the previous post, we proved one direction — that $\textsf{IP} \subseteq \textsf{PSPACE}$. In this post, we’re not yet going to prove the opposite direction — that $\textsf{PSPACE} \subseteq \textsf{IP}$ — but we’ll give an interactive proof for a specific problem that is already quite surprising, and illustrates most of the main ideas that go into the proof of $\textsf{PSPACE} \subseteq \textsf{IP}$ in a somewhat simpler setting. (In a post which will probably appear at some indefinite point in the future, we’ll prove the full theorem, by extending these ideas to give an interactive proof for <em>every</em> problem in $\textsf{PSPACE}$.)</p> <p>The specific problem we’ll consider is the problem of counting the number of solutions to a Boolean formula.</p> <div class="definition"> We define $\textsf{Count-SAT}$ as the following decision problem: <ul> <li> <b>Input:</b> a Boolean formula $\varphi$ in variables $x_1$, $\ldots$, $x_n$, and an integer $k$. </li> <li> <b>Decide:</b> whether there are at least $k$ satisfying assignments to $\varphi$. </li> </ul> </div> <div class="theorem"> There is an interactive proof for $\textsf{Count-SAT}$. </div> <p>Note that this means there’s also an interactive proof for the problem $\textsf{UNSAT}$, where the prover wants to convince the verifier that a formula is <em>not</em> unsatisfiable — a formula $\varphi$ in $x_1$, $\ldots$, $x_n$ is unsatisfiable if and only if $\neg \varphi$ has at least $2^n$ satisfying assignments, and this is a statement that a prover can convince a verifier of using the $\textsf{Count-SAT}$ protocol. This is already quite surprising.</p> <p>In the rest of the post, we’ll explain this protocol. The content of this post is based on lectures from 18.404 (the lectures from December 7 and 12) and 18.405 (the lecture from April 16).</p> <h1 id="some-notation">Some notation</h1> <p>First, here’s some notation we’ll use throughout the proof. Throughout this post, we’ll assume $\varphi$ is a Boolean formula in $n$ variables $x_1$, $\ldots$, $x_n$. We’re going to think of Boolean values as $0$ (which corresponds to $\texttt{False}$) and $1$ (which corresponds to $\texttt{True}$) — so $\varphi$ defines a function \(\{0, 1\}^n \to \{0, 1\}\).</p> <p>We’ll use $\texttt{#}\textsf{SAT}(\varphi)$ to refer to the number of satisfying assignments to $\varphi$, which we can write as</p> <div class="eqn"> \[\texttt{#}\textsf{SAT}(\varphi) = \sum_{a_1, \ldots, a_n \in \{0, 1\}} \varphi(a_1, \ldots, a_n).\] </div> <p>(This is because we’re summing over all possible assignments; and each satisfying assignment we plug in will contribute $1$ to the sum, while each unsatisfying assignment will contribute $0$.)</p> <p>We’ll also set up some notation for plugging in ‘partial assignments’ — for a string $b = b_1\ldots b_i$ (representing an assignment of the first $i$ variables $x_1$, $\ldots$, $x_i$), we use $\varphi_b$ to denote the formula in $x_{i + 1}$, $\ldots$, $x_n$ obtained by plugging in $x_1 = b_1$, $\ldots$, $x_i = b_i$. Then $\texttt{#}\textsf{SAT}(\varphi_b)$ denotes the number of satisfying assignments (to the remaining variables $x_{i + 1}$, $\ldots$, $x_n$) of $\varphi_b$, or equivalently the number of satisfying assignments to $\varphi$ that begin with $b_1$, $\ldots$, $b_i$; we can write this as</p> <div class="eqn"> \[\texttt{#}\textsf{SAT}(\varphi_b) = \sum_{a_{i + 1}, \ldots, a_n \in \{0, 1\}} \varphi(b_1, \ldots, b_i, a_{i + 1}, \ldots, a_n).\] </div> <p>Note that if $b$ has length $n$ (i.e., $b = b_1\ldots b_n$), then $\texttt{#}\textsf{SAT}(\varphi_b)$ is just $\varphi(b_1, \ldots, b_n)$, while otherwise</p> <div class="eqn"> \[\texttt{#}\textsf{SAT}(\varphi_b) = \texttt{#}\textsf{SAT}(\varphi_{b0}) + \texttt{#}\textsf{SAT}(\varphi_{b1}).\] </div> <p>In words, this is because on the left-hand side we’re trying to count the number of satisfying assignments to $\varphi$ which begin with $x_1 = b_1$, $\ldots$, $x_i = b_i$, and on the right-hand side we’re splitting this count into the two cases $x_{i + 1} = 0$ and $x_{i + 1} = 1$. (This also can be seen directly from <span class="crossref">(2).</span>)</p> <p>Finally, we’ll use $\varepsilon$ to denote the empty string (so $\varphi_\varepsilon = \varphi$).</p> <h1 id="a-first-attempt">A first attempt</h1> <p>First, here’s an <em>attempt</em> to get an interactive proof for $\textsf{Count-SAT}$. This won’t work — in particular, the verifier will be extremely inefficient — but trying to figure out how to fix it motivates the actual protocol.</p> <ul> <li> First, the prover says, <span class="mypurple">'I claim $\texttt{#}\textsf{SAT}(\varphi) = k_\varepsilon$'</span> for some integer $k_\varepsilon$ (i.e., they send the verifier an integer $k_\varepsilon$, which the verifier interprets as making this claim). The verifier checks that $k_\varepsilon \geq k$, and <span class="myaqua">rejects</span> if not. (This is because the entire goal of the procedure is for the prover to convince the verifier that $\texttt{#}\textsf{SAT}(\varphi)$ is at least $k$, so if the prover's already telling them that it's a quantity <em>less</em> than $k$, then they should automatically reject.) </li> <li> Now the verifier thinks, <span class="myaqua">'Well, why should I believe you?'</span> And the prover says, <span class="mypurple">'Well, the reason I know $\texttt{#}\textsf{SAT}(\varphi) = k_\varepsilon$ is because $\texttt{#}\textsf{SAT}(\varphi_{0}) = k_{0}$ and $\texttt{#}\textsf{SAT}(\varphi_{1}) = k_{1}$'</span> (by sending over two new integers $k_{0}$ and $k_{1}$). And the verifier checks that this makes sense (i.e., that the new claims justify the old claim) &mdash; they know from <span class="crossref">(3)</span> that $\texttt{#}\textsf{SAT}(\varphi) = \texttt{#}\textsf{SAT}(\varphi_{0}) + \texttt{#}\textsf{SAT}(\varphi_{1})$, so they check that $k_\varepsilon = k_0 + k_1$ and <span class="myaqua">reject</span> if not. </li> <li> Now the verifier thinks, <span class="myaqua">'Well, if your new claims about $\texttt{#}\textsf{SAT}(\varphi_{\texttt{T}})$ and $\texttt{#}\textsf{SAT}(\varphi_{\texttt{F}})$ are true, then your original claim is too. But why should I believe these new claims?'</span> And the prover says, <span class="mypurple">'Well, the reason I know $\texttt{#}\textsf{SAT}(\varphi_0) = k_0$ is because $\texttt{#}\textsf{SAT}(\varphi_{00}) = k_{00}$ and $\texttt{#}\textsf{SAT}(\varphi_{01}) = k_{01}$, and the reason I know $\texttt{#}\textsf{SAT}(\varphi_{1}) = k_{1}$ is because $\texttt{#}\textsf{SAT}(\varphi_{10}) = k_{10}$ and $\texttt{#}\textsf{SAT}(\varphi_{11}) = k_{11}$'</span> (so they're sending over four new integers $k_{00}$, $k_{01}$, $k_{10}$, and $k_{11}$). And the verifier checks that these statements make sense (meaning that the new claims justify the old claims) &mdash; they check that $k_0 = k_{00} + k_{01}$ and that $k_1 = k_{10} + k_{11}$, and <span class="myaqua">reject</span> if not. </li> <li> This continues &mdash; at the start of the $i$th step, the prover has made claims of the form <span class="mypurple">'$\texttt{#}\textsf{SAT}(\varphi_b) = k_b$'</span> for all $b = b_1\ldots b_{i - 1}$ (i.e., they've considered all ways to set the first $i - 1$ variables, and claimed that each of these corresponds to a certain number of satisfying assignments). The verifier thinks, <span class="myaqua">'Well, why should I believe these claims?'</span> And for each $b$, the prover justifies the claim $\texttt{#}\textsf{SAT}(\varphi_b) = k_b$ by sending over two new claimed counts $k_{b0}$ and $k_{b1}$ &mdash; so for each $b$, they're making a statement <span class="mypurple">'Well, the reason I know $\texttt{#}\textsf{SAT}(\varphi_b) = k_b$ is because $\texttt{#}\textsf{SAT}(\varphi_{b0}) = k_{b0}$ and $\texttt{#}\textsf{SAT}(\varphi_{b1}) = k_{b1}$.'</span> And the verifier checks that these new claims justify the old claims &mdash; they check that $k_b = k_{b0} + k_{b1}$ for all $b$, and <span class="myaqua">reject</span> if not. </li> <li> Finally, after $n$ steps, the prover has made claims of the form <span class="mypurple">'$\texttt{#}\textsf{SAT}(\varphi_b) = k_b$'</span> for all $b = b_1\ldots b_n$ (corresponding to plugging in values for <em>all</em> the variables), and the verifier is satisfied that if these claims are true, then so is the original claim. And the verifier can check these claims themselves &mdash; we have $\texttt{#}\textsf{SAT}(\varphi_b) = \varphi(b_1, \ldots, b_n)$, so the verifier can simply plug this assignment into $\varphi$ and check that it evaluates to the claimed value $k_b$. Finally, they <span class="myaqua">reject</span> if one of these checks fail (as now they've caught the prover in a lie) and <span class="myaqua">accept</span> if all the checks pass (they know all the prover's claims in the final step were correct, and since they're satisfied that the prover's claims from the $i$th step justify their claims from the $(i - 1)$th step for all $i$, this means they're satisfied that the original claim was correct too). </li> </ul> <p>This procedure certainly satisfies correctness and soundness, but it’s <em>extremely</em> inefficient — on the $i$th step, the prover is sending over $2^i$ different numbers (one for each of the ways to set the first $i$ variables). So the messages get exponentially long, and the verifier is going to run in exponential time. This is a problem, as we want the verifier to be <em>polynomial</em>-time.</p> <center><img src="/assets/img/ipcount1.png" width="300" height="auto"/></center> <p>The problem with this procedure — i.e., the reason it’s so inefficient — is that every time the verifier asks the prover to justify a claim $\texttt{#}\textsf{SAT}(\varphi_b) = k_b$, the prover responds with <em>two</em> new claims — for $\varphi_{b\texttt{T}}$ and $\varphi_{b\texttt{F}}$ — and the verifier then has to check <em>both</em> claims. This gives the protocol the structure of a binary tree (as shown above), and means it grows to have exponential size. So if we want to fix this protocol to be efficient, we have to somehow fix this issue — we have to make it so that for each claim $\texttt{#}\textsf{SAT}(\varphi_b) = k_b$ that the prover makes, when they provide justification for it by making two new claims $\texttt{#}\textsf{SAT}(\varphi_{b\texttt{T}}) = k_{b\texttt{T}}$ and $\texttt{#}\textsf{SAT}(\varphi_{b\texttt{F}}) = k_{b\texttt{F}}$, the verifier only needs to be convinced of <em>one</em> statement to be convinced of both of these claims (rather than asking to be convinced of each claim separately).</p> <div class="remark"> When I first saw this proof, the first thing I thought was, why doesn't the verifier just choose a random one of these two claims and ask the prover to convince them of just that one (i.e., they flip a coin and ask the prover either to convince them that $\texttt{#}\textsf{SAT}(\varphi_{b0}) = k_{b0}$ or that $\texttt{#}\textsf{SAT}(\varphi_{b1}) = k_{b1}$, rather than asking the prover to convince them of both)? <br/><br/> But this doesn't work because it won't satisfy soundness. To see this, imagine that $\texttt{#}\textsf{SAT}(\varphi)$ is $50$, but a cheating prover is trying to convince the verifier that it's actually $100$. Then the cheating prover can't give honest values of <em>both</em> $\texttt{#}\textsf{SAT}(\varphi_{0})$ and $\texttt{#}\textsf{SAT}(\varphi_{2})$, because the verifier would catch them (the correct values sum to $\texttt{#}\textsf{SAT}(\varphi) = 50$, while the verifier is checking that the values the prover sends sum to $k_\varepsilon = 100$). But they can give a honest value for <em>one</em> of them &mdash; for example, if the correct values are $40$ and $10$, then the prover can instead claim the values of $40$ and $60$ (i.e., they send $k_0 = 40$ and $k_1 = 60$). <br/><br/> Then if the verifier chooses the first claim &mdash; that $\texttt{#}\textsf{SAT}(\varphi_0) = 40$ &mdash; and asks the prover to convince them of just this claim, the prover can successfully do so, because this claim is true. So they'll have gotten away with their original lie, and the verifier will incorrectly have been convinced that $\texttt{#}\textsf{SAT}(\varphi) = 100$. <br/><br/> Meanwhile, if the verifier chooses the second claim &mdash; that $\texttt{#}\textsf{SAT}(\varphi_{1}) = 60$ &mdash; and asks the prover to convince them of just this claim, then at least the prover hasn't <em>immediately</em> gotten away with things, because the statement they're trying to convince the verifier of is still false. <br/><br/> But now the same thing happens &mdash; for example, imagine that the correct values of $\texttt{#}\textsf{SAT}(\varphi_{10})$ and $\texttt{#}\textsf{SAT}(\varphi_{11})$ are $3$ and $7$. Then the prover can't send the correct values of both (since $3 + 7$ is not $60$), but they <em>can</em> send the correct value for one of them &mdash; for example, they can send $3$ and $57$. And then if the verifier asks them to justify $\texttt{#}\textsf{SAT}(\varphi_{10}) = 3$, they'll be able to do so, because this statement is true &mdash; so they'll have gotten away with their lie again. <br/><br/> This means the prover has a $\frac{1}{2}$ probability of getting away with a lie at each step (i.e., the claim they were trying to convince the verifier of at the start of the $i$th step was false, but the claim they're trying to convince the verifier of at the end of the $i$th step is actually true &mdash; which means they can successfully convince the verifier). So the probability that they <em>never</em> get away with a lie, and the verifier really catches them in the end and rejects, is just $\frac{1}{2^n}$. This is pretty terrible, as we want the verifier to reject with high probability. </div> <p>So our goal is to find a way of compressing the two claims $\texttt{#}\textsf{SAT}(\varphi_{b0}) = k_{b0}$ and $\texttt{#}\textsf{SAT}(\varphi_{b1}) = k_{b1}$ into a single claim $(\star)$, and finding a <em>single</em> statement $(\star\star)$ that the verifier can ask the prover to convince them of that would suffice to convince them of $(\star)$. This statement is going to be randomized, but we’ll have to do something better than just randomly choosing one of the two claims — we need the probability that the prover ‘gets away with a lie’ at each step (meaning that $(\star)$ is false but $(\star\star)$ is true) to be much smaller than $\frac{1}{2}$. And the key idea that’s going to let us do this is <span class="vocab">arithmetization</span>.</p> <h1 id="arithmetization">Arithmetization</h1> <p>We’ve got a Boolean formula $\varphi$, which takes inputs in \(\{0, 1\}^n\) and spits out some output in \(\{0, 1\}\). But the idea is that instead of thinking of $\varphi$ as a Boolean formula, we’re going to think of it as a polynomial over some finite field $\mathbb{F} = \mathbb{F}_p$ (where $p$ is a large prime we’ll fix at the start of the protocol).</p> <p>To arithmetize $\varphi$ (i.e., to turn it into a polynomial), we can use the following correspondences:</p> <ul> <li> $\neg x$ becomes $1 - x$. </li> <li> $x \wedge y$ becomes $xy$. </li> <li> $x \vee y$ becomes $x + y - xy$. </li> </ul> <p>The point is that the arithmetic expressions on the right match the Boolean ones on the left when we plug in \(\{0, 1\}\)-valued inputs, so this is a ‘faithful’ way of representing Boolean operations.</p> <div class="example"> Suppose that we begin with the Boolean formula $\varphi(x_1, x_2, x_3) = x_1 \vee (\neg x_2 \wedge x_3)$. Then to arithmetize it, we first replace $\neg x_2$ with $1 - x_2$, then we replace $(1 - x_2) \wedge x_3$ with $(1 - x_2)x_3$, and finally we replace $x_1 \vee (1 - x_2)x_3$ with $x_1 + (1 - x_2)x_3 - x_1(1 - x_2)x_3$, to get the polynomial \[\varphi(x_1, x_2, x_3) = x_1 + (1 - x_2)x_3 - x_1(1 - x_2)x_3.\] </div> <p>If we only care about Boolean (i.e., \(\{0, 1\}\)-valued) inputs, then it doesn’t matter whether we think of $\varphi$ as a formula or a polynomial — we’ll get the same outputs either way. But the advantage of thinking of $\varphi$ as a polynomial is that it allows us to plug in quantities that are <em>not</em> Boolean — for example, now it makes sense to talk about plugging in $x_1 = 5$ (which would make no sense if viewing $\varphi$ just as a Boolean formula).</p> <div class="remark"> The verifier might not be able to write down $\varphi$ as a polynomial in $x_1$, $\ldots$, $x_n$ (this polynomial could potentially have a huge number of terms), but they definitely <em>can</em> evaluate it at any specific input &mdash; they can simply evaluate it one operation at a time, using arithmetic operations instead of Boolean ones. For example, if they wanted to find $\varphi(5, 3, 7)$ for the $\varphi$ from <span class="crossref">Example 6</span>, they'd first think of it as $5 \vee (\neg 3 \wedge 7)$. Then they'd first evaluate $\neg 3$ as $1 - 3 = -2$; then they'd evaluate $-2 \wedge 7$ as $(-2)(7) = -14$; and finally they'd evaluate $5 \vee (-14)$ as $5 + (-14) - 5(-14) = 61$. <br/><br/> And in the protocol, this is all we'll expect the verifier to do with $\varphi$ &mdash; all other computations with $\varphi$ (as a polynomial) will be done on the prover's end. </div> <p>For our purposes, it’ll be important that the polynomial version of $\varphi$ has decently low degree.</p> <div class="fact"> The degree of $\varphi$ as a polynomial is at most the size of $\varphi$ as a formula. </div> <p>We’ll refer to these quantities as $\textsf{deg}(\varphi)$ and $\textsf{size}(\varphi)$, respectively. We measure the size of a Boolean formula by the number of appearances of variables — for example, we’d say that $\textsf{size}(x_1 \vee (\neg x_1 \wedge x_3))$ is $3$ (there’s three appearances of variables, namely $x_1$, $x_1$, and $x_3$). Then the reason this fact is true is essentially that each time we perform the arithmetic version of an $\wedge$ or $\vee$ on two smaller formulas, we’re at worst adding together their degrees.</p> <p>We’ve previously defined the notation $\texttt{#}\textsf{SAT}(\varphi_b)$ where $b = b_1\ldots b_i$ is an assignment of <em>Boolean</em> values to $x_1$, $\ldots$, $x_i$ — we defined this as the number of ways to set Boolean values \(a_{i + 1}, \ldots, a_n \in \{0, 1\}\) for the remaining variables $x_{i + 1}$, $\ldots$, $x_n$ that give satisfying assignments. We’d now like to define $\texttt{#}\textsf{SAT}(\varphi_r)$ where $r = r_1\ldots r_i$ is an assignment of <em>arbitrary</em> values from $\mathbb{F}$ to $x_1$, $\ldots$, $x_i$ (rather than just $0$’s and $1$’s). This definition no longer makes sense, but the equation <span class="crossref">(2)</span> for $\texttt{#}\textsf{SAT}(\varphi_b)$ <em>does</em> make sense, so we’ll simply take this equation to be our definition of $\texttt{#}\textsf{SAT}(\varphi_r)$ — i.e., we define</p> <div class="eqn"> \[\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_i}) = \sum_{a_{i + 1}, \ldots, a_n \in \{0, 1\}} \varphi(r_1, \ldots, r_i, a_{i + 1}, \ldots, a_n).\] </div> <p>Then the equation <span class="crossref">(3)</span> still holds — if $r$ has length less than $n$, then</p> <div class="eqn"> \[\texttt{#}\textsf{SAT}(\varphi_r) = \texttt{#}\textsf{SAT}(\varphi_{r0}) + \texttt{#}\textsf{SAT}(\varphi_{r1}),\] </div> <p>while if $r = r_1\ldots r_n$ has length $n$, then $\texttt{#}\textsf{SAT}(\varphi_r)$ is just $\varphi(r_1, \ldots, r_n)$.</p> <h1 id="the-actual-protocol">The actual protocol.</h1> <p>Now we’re ready to describe an interactive proof protocol that <em>does</em> work.</p> <ul> <li> We're going to work over some finite field $\mathbf{F} = \mathbb{F}_p$, so we first need to fix a suitable prime $p$. For this, we'll have the prover send over a prime $p \in [2^n \cdot \textsf{size}(\varphi), 2^{n + 1} \cdot \textsf{size}(\varphi)]$. We need a way of making sure that $p$ is actually prime (so that if a cheating prover sends over some $p$ which isn't prime, the verifier catches them). We can do this because primality testing is in $\textsf{NP}$ (this is nontrivial and involves a bit of number theory &mdash; for example, see <a href="https://en.wikipedia.org/wiki/Primality_certificate" target="_blank">this Wikipedia article</a>), so the prover can send over a certificate showing that $p$ is prime, and the verifier can check it. <div class="remark"> In fact, primality testing is actually in $\textsf{P}$, so the verifier could check that $p$ is prime on their own; but this is a much more difficult result. </div> <div class="remark"> The specific size of $p$ is not particularly important. We need $p &gt; 2^n$, because what the prover will be doing is really convincing the verifier of the value of $\texttt{#}\textsf{SAT}(\varphi)$ in $\mathbb{F}_p$ &mdash; and if $p$ were less than $2^n$ then this wouldn't be enough to recover the actual value of $\texttt{#}\textsf{SAT}(\varphi)$ (because of numbers wrapping around mod $p$). And we need $p \leq 2^{\textsf{poly}(n)}$ so that we can do computations with numbers in $\mathbb{F}_p$. But other than this, the value of $p$ doesn't matter (the bound we've got here will be way more than enough to ensure soundness). </div> Now that we've got $p$, we can proceed with the main part of the protocol (where all arithmetic is done over $\mathbb{F} = \mathbb{F}_p$). </li> <li> First, as in our failed attempt, the prover starts by saying <span class="mypurple">'I claim that $\texttt{#}\textsf{SAT}(\varphi) = k_0$'</span> for some $k_0$ (by sending over $k_0$). (The indices we're going using here are a bit different from the ones in our failed attempt &mdash; they'll be integers rather than bit-strings.) The verifier checks that $k_0 \geq k$, and <span class="myaqua">rejects</span> if not. </li> <li> Now the verifier again thinks, <span class="myaqua">'Well, why should I believe you?'</span> In our failed attempt, the prover tried to justify their claim by making new claims about the values of $\texttt{#}\textsf{SAT}(\varphi_0)$ and $\texttt{#}\textsf{SAT}(\varphi_1)$. Here, they'll do something different &mdash; they'll make a single claim about the value of $\texttt{#}\textsf{SAT}(\varphi_z)$ as a <em>polynomial</em> in $z$. <br/><br/> What does this mean? In <span class="crossref">(5)</span>, we defined \[\texttt{#}\textsf{SAT}(\varphi_{r_1}) = \sum_{a_2, \ldots, a_n \in \{0, 1\}} \varphi(r_1, a_2, \ldots, a_n)\] for any $r_1 \in \mathbb{F}$. We can imagine thinking of $r_1$ as a variable $z$ &mdash; then $\texttt{#}\textsf{SAT}(\varphi_z)$ is the single-variable polynomial in $z$ obtained by summing the $2^{n - 1}$ polynomials $\varphi(z, a_2, \ldots, a_n)$. This is some polynomial in $z$, and it'll have degree at most $\textsf{deg}(\varphi) \leq \textsf{size}(\varphi)$. <div class="example"> Suppose that $\varphi(x_1, x_2, x_3) = x_1 \vee (\neg x_1 \wedge x_2 \wedge x_3)$, which becomes the polynomial \[\varphi(x_1, x_2, x_3) = x_1 + (1 - x_1)x_2x_3 - x_1(1 - x_1)x_2x_3.\] Then to compute $\texttt{#}\textsf{SAT}(\varphi_z)$ we want to plug in $z$ for $x_1$, and sum over all ways to plug in $a_2, a_3 \in \{0, 1\}$ for $x_2$ and $x_3$. So we'll have a sum over four terms: <ul> <li> $(a_2, a_3) = (0, 0)$ gives $z + (1 - z)0\cdot 0 - z(1 - z)0\cdot 0 = z$. </li> <li> $(a_2, a_3) = (0, 1)$ and $(a_2, a_3) = (1, 0)$ similarly give $z$. </li> <li> $(a_2, a_3) = (1, 1)$ gives $z + (1 - z)1\cdot 1 - z(1 - z)1\cdot 1 = 1 - z + z^2$. </li> </ul> Summing these up, we get $\texttt{#}\textsf{SAT}(\varphi_z) = z + z + z + (1 - z + z^2) = 1 + 2z + z^2$. </div> <div class="remark"> It might take exponentially long for the prover to <em>compute</em> the polynomial $\texttt{#}\textsf{SAT}(\varphi_z)$, but we don't care &mdash; the prover is computationally unbounded. What's important is that this polynomial has low degree, so the prover can write it down succinctly &mdash; in the form $\sum a_iz^i$ &mdash; and the verifier can efficiently do computations with it. </div> So the prover says, <span class="mypurple">'Well, I know $\texttt{#}\textsf{SAT}(\varphi) = k_0$ because $\texttt{#}\textsf{SAT}(\varphi_z) = Q_1(z)$'</span> &mdash; so they're sending the verifier a polynomial $Q_1(z)$ of degree at most $\textsf{size}(\varphi)$. (If the polynomial they send has degree higher than this, the verifier immediately knows it's wrong, so they <span class="myaqua">reject</span>.) <br/><br/> And the first point of this idea is that if the verifier's got $\texttt{#}\textsf{SAT}(\varphi_z)$ as a polynomial in $z$, then they can automatically compute $\texttt{#}\textsf{SAT}(\varphi_0)$ and $\texttt{#}\textsf{SAT}(\varphi_1)$ themselves, by simply plugging in $z = 0$ and $z = 1$. So we've found a way of bundling the two claims from our failed attempt into one single claim. <br/><br/> So the verifier first checks that this new claim does justify the old claim &mdash; they know from <span class="crossref">(5)</span> that $\texttt{#}\textsf{SAT}(\varphi) = \texttt{#}\textsf{SAT}(\varphi_0) + \textsf{SAT}(\varphi_1)$, so they check that $k_\varepsilon = Q_1(0) + Q_1(1)$ and <span class="myaqua">reject</span> if not. </li> <li> Now the verifier thinks, <span class="myaqua">'Well, if you've really given me the correct polynomial $\texttt{#}\textsf{SAT}(\varphi_z)$, then your original claim about $\texttt{#}\textsf{SAT}(\varphi)$ is true. But why should I believe you've really given me the correct polynomial?'</span> <br/><br/> And so the verifier is going to choose a uniform random $r_1 \in \mathbb{F}$ and say, <span class="myaqua">'Okay, convince me that your polynomial is correct at $r_1$, and then I'll believe you that it's actually correct.'</span> In other words, instead of asking the prover to convince them that $\texttt{#}\textsf{SAT}(\varphi_z)$ and $Q_1(z)$ are equal as polynomials, the verifier is choosing a random point $r_1$ to evaluate them at, and asking the prover to convince them that they're equal at $r_1$ &mdash; i.e., that $\texttt{#}\textsf{SAT}(\varphi_{r_1}) = Q_1(r_1)$. (And if the prover manages to convince them of this, then they'll believe the prover's claim that the two polynomials are equal.) <div class="remark"> Why do we need to plug in some $r_1$ &mdash; why don't we want the verifier to just ask the prover to convince them of the full claim $\texttt{#}\textsf{SAT}(\varphi_z) = Q_1(z)$? The problem with doing this is that it'd blow up the complexity of the claims. What's nice about what we've done here is that we started with the prover trying to prove a statement that $\texttt{#}\textsf{SAT}(\varphi)$ is equal to a certain integer, where $\texttt{#}\textsf{SAT}(\varphi)$ is a sum of $2^n$ polynomials as in <span class="crossref">(4)</span>; and we've ended up with them trying to prove a statement that $\texttt{#}\textsf{SAT}(\varphi_{r_1})$ is equal to another certain integer, where $\texttt{#}\textsf{SAT}(\varphi_{r_1})$ is a sum over $2^{n - 1}$ polynomials as in <span class="crossref">(4)</span> (we're no longer summing over $a_1$). This is essentially a statement of the same form as the original one (but with one fewer variable), so we can iterate &mdash; we can ask the prover to justify this claim in the same way. <br/><br/> Meanwhile, if we <em>didn't</em> plug in a value $r_1$ &mdash; and instead left $z$ as a variable &mdash; then if we tried to iterate (leaving everything as a variable), in the end we'd be asking the prover to prove a statement of the form $\texttt{#}\varphi_{z_1\ldots z_n} = Q(z_1, \ldots, z_n)$ (where we've got polynomials in $n$ variables rather than just $1$). And this is bad, because these polynomials could be enormous (unlike the one-variable polynomials we'll get from the actual proof). </div> <div class="remark"> Why is this a reasonable thing to do? We saw in <span class="crossref">Remark 5</span> that randomly choosing to check either the prover's claim about $\texttt{#}\textsf{SAT}(\varphi_0)$ or their claim about $\texttt{#}\textsf{SAT}(\varphi_1)$ doesn't work (since a cheating prover has a $\frac{1}{2}$ probability of getting away with a lie at each step &mdash; if one of these two claims is wrong, there's only a $\frac{1}{2}$ probability we choose to investigate the wrong claim). In contrast, here in some sense the prover is making a claim about $\texttt{#}\textsf{SAT}(\varphi_{r_1})$ for <em>all</em> $r_1 \in \mathbb{F}$, by giving the verifier $\texttt{#}\textsf{SAT}(\varphi_z)$ as a polynomial, and the verifier is choosing a random $r_1 \in \mathbb{F}$ to check. <br/><br/> And the key difference is that if the prover gives us an <em>incorrect</em> polynomial (i.e., they're lying), then this polynomial is wrong on nearly all inputs $r_1 \in \mathbb{F}$ (because two low-degree polynomials can't agree in too many places). So the probability they get away with the lie &mdash; i.e., the new statement they're trying to prove is true &mdash; is tiny. This shows why arithmetization is nice &mdash; if we could only plug in $0$ and $1$, then we'd only have a $\frac{1}{2}$ probability of plugging in something that preserved falsity (i.e., such that the new claim the prover is trying to prove is still false). But if we can plug in arbitrary values from a much larger field, then this probability is much higher. <br/><br/> (We'll explain this in more detail when we prove soundness, but this is the main intuition behind why the protocol is sound.) </div> So the verifier has chosen a random $r_1 \in \mathbb{F}$ and computed $Q_1(r_1)$, which we'll call $k_1$; and now they're challenging the prover to convince them that $\texttt{#}\textsf{SAT}(\varphi_{r_1}) = k_1$. </li> <li> For the prover to do so, we know that $\texttt{#}\textsf{SAT}(\varphi_{r_1}) = \texttt{#}\textsf{SAT}(\varphi_{r_10}) + \texttt{#}\textsf{SAT}(\varphi_{r_11})$ from <span class="crossref">(5)</span>, so the prover is going to send over $\texttt{#}\textsf{SAT}(\varphi_{r_1z})$ as a polynomial in $z$ &mdash; this means we plug in the number $r_1$ for $x_1$, the variable $z$ for $x_2$, and all possible $\{0, 1\}$-assignments to the remaining variables, i.e., \[\texttt{#}\textsf{SAT}(\varphi_{r_1z}) = \sum_{a_3, \ldots, a_n \in \{0, 1\}} \varphi(r_1, z, a_3, \ldots, a_n).\] <div class="example"> Let $\varphi$ be the same formula from <span class="crossref">Example 11</span>, which as a polynomial is \[\varphi(x_1, x_2, x_3) = x_1 + (1 - x_1)x_2x_3 - x_1(1 - x_1)x_2x_3,\] and suppose the verifier chose $r_1 = 5$. Then the polynomial the prover is supposed to send is \[\texttt{#}\textsf{SAT}(\varphi_{5z}) = \varphi(5, z, 0) + \varphi(5, z, 1).\] The first term is $\varphi(5, z, 0) = 5 + (-4)z\cdot 0 - 5(-4)z\cdot 0 = 5$, while the second term is $\varphi(5, z, 1) = 5 + (-4)z\cdot 1 - 5(-4)z\cdot 1 = 5 + 16z$, so \[\texttt{#}\textsf{SAT}(\varphi_{5z}) = 5 + (5 + 16z) = 10 + 16z.\] </div> So the prover says, <span class="mypurple">'The reason I know $\texttt{#}\textsf{SAT}(\varphi_{r_1}) = k_1$ is because $\texttt{#}\textsf{SAT}(\varphi_{r_1}z) = Q_2(z)$'</span> &mdash; this means they're sending the verifier another polynomial $Q_2(z)$ of degree at most $\textsf{size}(\varphi)$. And the verifier again checks that this justifies the previous claim &mdash; i.e., that $k_1 = Q_2(0) + Q_2(1)$ &mdash; and <span class="myaqua">rejects</span> if not. </li> <li> And the verifier again thinks, <span class="myaqua">'Well, if you've given me the correct polynomial $\texttt{#}\textsf{SAT}(\varphi_{r_1z})$, then your claim about $\texttt{#}\textsf{SAT}(\varphi_{r_1})$ is true. But why should I believe your polynomial?'</span> And so they again choose a random $r_2 \in \mathbb{F}$ to evaluate it at, and they say, <span class="myaqua">'Okay, convince me that your polynomial is correct at $r_2$, and then I'll believe you that it's actually correct.'</span> So they're computing $Q_2(r_2)$, which we call $k_2$, and then challenging the prover to convince them that $\texttt{#}\textsf{SAT}(\varphi_{r_1r_2}) = k_2$. </li> <li> This continues &mdash; at the start of the $i$th step, the prover is trying to convince the verifier of a claim $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}}) = k_{i - 1}$ (where $r_1, \ldots, r_{i - 1} \in \mathbb{F}$ have been chosen uniformly at random by the verifier). To do so, they send over $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}z})$ as a polynomial in $z$ &mdash; this is defined as \[\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}z}) = \sum_{a_{i + 1}, \ldots, a_n \in \{0, 1\}} \varphi(r_1, \ldots, r_{i - 1}, z, a_{i + 1}, \ldots, a_n).\] So they say, <span class="mypurple">'The reason I know $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}}) = k_{i - 1}$ is because $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}z}) = Q_i(z)$,'</span> by sending over a polynomial $Q_i(z)$ of degree at most $\textsf{size}(\varphi)$. And the verifier first checks that this justifies the previous claim according to <span class="crossref">(5)</span> &mdash; i.e., that $k_{i - 1} = Q_i(0) + Q_i(1)$ &mdash; and <span class="myaqua">rejects</span> if not. <br/><br/> And then the verifier thinks, <span class="myaqua">'Well, why should I believe your polynomial?'</span> So they choose a random point $r_i \in \mathbb{F}$ to evaluate it at, and they say, <span class="myaqua">'Okay, convince me that your polynomial is correct at $r_i$, and then I'll believe you that it's actually correct.'</span> In other words, they're computing $k_i = Q_i(r_i)$ and then asking the prover to convince them that $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_i}) = k_i$. </li> <li> Finally, after the $n$th step, the prover is trying to convince the verifier that $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_n}) = k_n$, for some $r_1, \ldots, r_n \in \mathbb{F}$ (which have been randomly chosen by the verifier). And the verifier can actually just check this claim themselves &mdash; by definition we have \[\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_n}) = \varphi(r_1, \ldots, r_n),\] and the verifier can plug all these values into the arithmetized version of $\varphi$ (as discussed in <span class="crossref">Remark 7</span>) to compute the right-hand side and check that it's equal to $k_n$; they <span class="myaqua">accept</span> if it is and <span class="myaqua">reject</span> if it isn't. </li> </ul> <p>Here’s a more succinct description of what actually occurs in this protocol.</p> <div class="algorithm"> On input $\varphi$ (where $\varphi$ is a Boolean formula in $x_1$, $\ldots$, $x_n$): <ul> <li> The prover sends the verifier a prime $p \in [2^n \cdot \textsf{size}(\varphi), 2^{n + 1}\cdot \textsf{size}(\varphi)]$ together with a proof that $p$ is prime, which the verifier checks; all arithmetic will be done over $\mathbb{F} = \mathbb{F}_p$. </li> <li> The prover sends the verifier an integer $k_0$, and the verifier checks that $k_0 \geq k$ (and <span class="myaqua">rejects</span> if not). </li> <li> For each $i = 1$, $\ldots$, $n$: <ul> <li> The prover sends the verifier a single-variable polynomial $Q_i(z)$. The verifier checks that $\textsf{deg}(Q_i) \leq \textsf{size}(\varphi)$ and $k_{i - 1} = Q_i(0) + Q_i(1)$, and <span class="myaqua">rejects</span> if not. </li> <li> The verifier chooses $r_i \in \mathbb{F}$ uniformly at random and sends it to the prover. </li> <li> We set $k_i = Q_i(r_i)$ (which both parties can compute). </li> </ul> </li> <li> Finally, the verifier checks that $k_n = \varphi(r_1, \ldots, r_n)$ by plugging $r_1$, $\ldots$, $r_n$ into $\varphi$ (using arithmetic operations instead of Boolean ones). They <span class="myaqua">accept</span> if yes and <span class="myaqua">reject</span> if no. </li> </ul> </div> <h1 id="correctness">Correctness</h1> <p>First, we’ll show that this protocol has perfect correctness — i.e., whenever $(\varphi, k)$ is a $\textsf{YES}$ instance of $\textsf{Count-SAT}$, there’s a good prover that makes the verifier <em>always</em> accept.</p> <p>The good prover simply tells the truth at each step, as in the more verbose description of the protocol — they first send $k_0 = \texttt{#}\textsf{SAT}(\varphi)$, and at each step they send the polynomial</p> <div> \[Q_i(z) = \texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}z}) = \sum_{a_{i + 1}, \ldots, a_n \in \{0, 1\}} \varphi(r_1, \ldots, r_{i - 1}, z, a_{i + 1}, \ldots, a_n).\] </div> <p>Then the verifier will always accept. Intuitively, we’ve built the verifier such that these are the answers they’re <em>expecting</em>, and they only reject when they catch the prover lying — so if the prover doesn’t ever lie, the verifier won’t ever reject.</p> <h1 id="soundness">Soundness</h1> <p>Now we’ll show that this protocol satisfies soundness — i.e., that whenever $(\varphi, k)$ is a $\textsf{NO}$ instance of $\textsf{Count-SAT}$, no matter what a cheating prover tries to do, the verifier will reject with high probability.</p> <p>Suppose we’ve got some cheating prover; we can assume the cheating prover is trying to <em>not</em> get caught, so they’ll never do anything that makes the verifier instantly reject. In particular, this means the value $k_0$ they send over at the start is a lie — i.e., it’s not the actual value of $\texttt{#}\textsf{SAT}(\varphi)$ — because if they sent over the correct value, the verifier would instantly reject (as it’s less than $k$).</p> <p>This means the polynomial $Q_1(z)$ they send over has to be a lie as well (i.e., it’s not the actual value of $\texttt{#}\textsf{SAT}(\varphi_z)$) — the verifier checks that $Q_1(0) + Q_1(1) = k_0$, but $\texttt{#}\textsf{SAT}(\varphi_0) + \texttt{#}\textsf{SAT}(\varphi_1)$ is $\texttt{#}\textsf{SAT}(\varphi)$, which is not $k_0$ (because $k_0$ is a lie). So if the cheating prover sent the correct polynomial, they’d immediately get caught.</p> <p>But then $Q_1(z)$ and $\texttt{#}\textsf{SAT}(\varphi_z)$ are both polynomials of degree at most $\textsf{size}(\varphi)$, which means they’re equal on at most $\textsf{size}(\varphi)$ points $r_1 \in \mathbb{F}$ (as their difference has at most this many roots). This means</p> <div> \[\mathbb{P}_{r_1}[Q_1(r_1) = \texttt{#}\textsf{SAT}(\varphi_{r_1})] \leq \frac{\textsf{size}(\varphi)}{p} \leq \frac{1}{2^n}\] </div> <p>(since we chose $p$ large enough).</p> <p>If this event occurs, then the cheating prover can successfully trick the verifier — even though their original claim that $\texttt{#}\textsf{SAT}(\varphi) = k_0$ was false, their new claim that $\texttt{#}\textsf{SAT}(\varphi_{r_1}) = Q_1(r_1)$ — is actually true, which means they can successfully convince the verifier of it (and therefore of the original false claim). But fortunately, this is very unlikely — with probability at least $1 - \frac{1}{2^n}$, the new claim is false as well.</p> <p>And the same thing happens at each step — suppose that the claim the cheating prover is trying to convince the verifier of at the start of the $i$th step, that $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}}) = k_{i - 1}$, is a lie. Then the prover has to lie about the polynomial $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}z})$ as well — i.e., they have to send some polynomial $Q_i(z)$ which doesn’t actually equal $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}z})$ — since if they sent the correct polynomial, the verifier would catch them when checking that $Q_i(0) + Q_i(1) = k_{i - 1}$. And then since $Q_i(z)$ and $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_{i - 1}z})$ are distinct polynomials of degree at most $\textsf{size}(\varphi)$, we have</p> <div> \[\mathbb{P}_{r_i}[Q_i(r_i) = \texttt{#}\textsf{SAT}(\varphi_{r1\ldots r_i})] \leq \frac{\textsf{size}(\varphi)}{p} \leq \frac{1}{2^n}.\] </div> <p>So with probability at least $1 - \frac{1}{2^n}$, the claim that the prover will be trying to convince the verifier of at the start of the next step — that $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_i}) = Q_i(r_i)$ — is a lie as well.</p> <p>Finally, since we’re doing this for $n$ steps and each preserves falsity with probability at least $1 - \frac{1}{2^n}$ (meaning that if the prover’s claim at the start of one step is a lie, then their claim at the start of the next step will be a lie with probability at least $1 - \frac{1}{2^n}$), this means that the prover’s claim after all $n$ steps is false with probability at least $(1 - \frac{1}{2^n})^n \geq 1 - \frac{n}{2^n}$ (meaning that $\texttt{#}\textsf{SAT}(\varphi_{r_1\ldots r_n})$ isn’t actually $k_n$). But the verifier checks this claim directly (by plugging in $r_1$, $\ldots$, $r_n$ into $\varphi$), so if it’s a lie, they’ll catch the prover and reject.</p> <p>This means the verifier rejects the cheating prover with probability at least $1 - \frac{n}{2^n}$, which is very close to $1$; so the protocol does satisfy soundness.</p>]]></content><author><name></name></author><category term="complexity,"/><category term="TCS"/><summary type="html"><![CDATA[An explanation of the interactive proof protocol for counting the number of satisfying assignments to a Boolean formula.]]></summary></entry><entry><title type="html">Anticoncentration of Random Subset Sums</title><link href="https://sanjanad1024.github.io/blog/2024/anticoncentration/" rel="alternate" type="text/html" title="Anticoncentration of Random Subset Sums"/><published>2024-06-03T00:00:00+00:00</published><updated>2024-06-03T00:00:00+00:00</updated><id>https://sanjanad1024.github.io/blog/2024/anticoncentration</id><content type="html" xml:base="https://sanjanad1024.github.io/blog/2024/anticoncentration/"><![CDATA[<p>I took 18.204 (Seminar in Discrete Math) this semester; this is a class where we each choose a topic and give a few presentations on it. My topic was anticoncentration. In this post, I’ll talk about a theorem that’s in some sense the starting point for all the things I presented on. (I may post about those things later.)</p> <h1 id="introduction">Introduction</h1> <p>In this post, we’ll consider the following question.</p> <div class="question"> Suppose we have $n$ nonzero real numbers $a_1$, $\ldots$, $a_n$, and we choose a random subset sum of these numbers &mdash; i.e., we consider the random variable $\varepsilon_1a_1 + \cdots + \varepsilon_na_n$ for $\varepsilon_i \in \{0, 1\}$ chosen uniformly and independently at random. How concentrated can this random variable be at a single point? </div> <p>In particular, we’re interested in proving <em>upper</em> bounds on how concentrated $\varepsilon_1a_1 + \cdots + \varepsilon_na_n$ can be at a single point $a$ — this means we want to upper-bound $\max_a \mathbb{P}[\varepsilon_1a_1 + \cdots + \varepsilon_na_n = a]$. This is why the topic is referred to as <span class="vocab">anticoncentration</span> — we’re trying to show that a random variable is <em>not</em> super concentrated at any point.</p> <p>This question was first considered by Littlewood and Offord (who were studying real roots of random polynomials) in a <a href="https://www.mathnet.ru/links/31fb3a11135873de2d81e19d30ad43aa/sm6161.pdf" target="_blank">paper</a> from 1943; they proved the following upper bound.</p> <div class="theorem" text="Littlewood&ndash;Offord 1943"> For all nonzero $a_1, \ldots, a_n \in \mathbb{R}$ and all $a \in \mathbb{R}$, we have \[\mathbb{P}[\varepsilon_1a_1 + \cdots + \varepsilon_na_n = a] \leq \frac{c\log n}{\sqrt{n}}\] (for some absolute constant $c &gt; 0$). </div> <p>This was later improved by Erdős to the following bound.</p> <div class="theorem" text="Erd&#337;s 1945"> For all nonzero $a_1, \ldots, a_n \in \mathbb{R}$ and all $a \in \mathbb{R}$, we have \[\mathbb{P}[\varepsilon_1a_1 + \cdots + \varepsilon_na_n = a] \leq \frac{\binom{n}{\lfloor n/2\rfloor}}{2^n}.\] </div> <p>As some intuition regarding how big the right-hand side is, by Stirling’s approximation $\binom{n}{\lfloor n/2\rfloor}$ is roughly $\frac{2^n}{\sqrt{n}}$ (ignoring constant factors), so this essentially removes the $\log n$ from the bound of Littlewood–Offord.</p> <p>Also, a nice thing is that this theorem is tight – the following construction achieves equality.</p> <div class="example"> Suppose that $a_1 = \cdots = a_n = 1$. Then for every $k$, we have \[\mathbb{P}[\varepsilon_1a_1 + \cdots + \varepsilon_n = k] = \frac{\binom{n}{k}}{2^n}\] (since getting a subset sum of $k$ corresponds to choosing exactly $k$ of the $\varepsilon_i$'s to be $1$). </div> <p>So the bound in <span class="crossref">Theorem 2</span> is the best bound we could possibly hope to get, and it turns out to be true — this essentially means that $\varepsilon_1a_1 + \cdots + \varepsilon_na_n$ is the most concentrated in the case where all the $a_i$’s are equal.</p> <p>Erdős proved this theorem using a very neat combinatorial argument, which I’ll explain in the rest of this post.</p> <h1 id="sperners-theorem">Sperner’s theorem</h1> <p>The proof is going to involve Sperner’s theorem regarding antichains of subsets of $[n]$, so we’ll first state and prove this theorem.</p> <div class="definition"> We say a collection $\mathcal{S}$ of subsets of $[n]$ is an <span class="vocab">antichain</span> if there do not exist any two distinct sets $A, B \in \mathcal{S}$ such that $A \subseteq B$. </div> <div class="example"> Letting $n = 4$, the collection of subsets $\{1, 2\}$, $\{1, 3, 4\}$, $\{2, 3, 4\}$ form an antichain (as no one of these subsets contains another). <br/><br/> On the other hand, $\{2, 4\}$, $\{1, 3, 4\}$, $\{2, 3, 4\}$ doesn't form an antichain, as the third contains the first. </div> <p>Sperner’s theorem considers the following question.</p> <div class="question"> Given $n$, what's the largest possible antichain of subsets of $[n]$? </div> <p>(By the size of an antichain $\mathcal{S}$, we mean the number of subsets in $\mathcal{S}$.)</p> <p>One potential construction of an antichain is to take all subsets of a fixed size $k$.</p> <div class="example"> For any $0 \leq k \leq n$, the collection $\mathcal{S} = \{A \subseteq [n] \mid \lvert A \rvert = k\}$ is an antichain of size $\binom{n}{k}$. </div> <p>To maximize the size of this antichain, we should take $k = \lfloor n/2\rfloor$. And Sperner’s theorem says essentially that this is the best we can do.</p> <div class="theorem" text="Sperner"> If $\mathcal{S}$ is an antichain of subsets of $[n]$, then $\lvert \mathcal{S} \rvert \leq \binom{n}{\lfloor n/2\rfloor}$. </div> <p>There are several proofs of this theorem; here’s a very cute one that I saw in 18.226 (involving a clever application of probabilistic methods).</p> <div class="proof"> Imagine we start with the set $\emptyset$ and add elements one at a time until we reach $[n]$ &mdash; so we start with the set $I_0 = \emptyset$, then add a random element $i_1 \in [n]$ to it to get the set $I_1 = \{i_1\}$, then add another random element $i_2 \in [n] \setminus \{i_1\}$ to get the set $I_2 = \{i_1, i_2\}$, and so on, until we've added all elements to finally end up with $I_n = \{i_1, \ldots, i_n\} = [n]$. This gives us a random sequence of sets $I_0 \subseteq I_1 \subseteq \cdots \subseteq I_n$. <br/><br/> On one hand, no matter what order we choose elements in, at most one set in $\mathcal{S}$ can appear in this sequence &mdash; if two sets $A$ and $B$ appeared in the sequence, then we'd have $A \subseteq B$ or $B \subseteq A$, contradicting the fact that $\mathcal{S}$ is supposed to be an antichain. <br/><br/> On the other hand, what's the <em>expected</em> number of sets $A \in \mathcal{S}$ to appear in this sequence? Each $I_k$ is a uniform random subset of $[n]$ with size $k$ (by symmetry), so if $\lvert A\rvert = k$, then the probability that $A$ appears in our sequence is \[\mathbb{P}[\text{$A$ appears in the sequence}] = \mathbb{P}[I_k = A] = \frac{1}{\binom{n}{k}}\] (since there's $\binom{n}{k}$ equally likely possibilities for $I_k$, one of which is $A$). So by linearity of expectation, the expected number of sets $A \in \mathcal{S}$ to appear in the sequence is \[\mathbb{E} \#\{A \in \mathcal{S} \mid \text{$A$ appears in the sequence}\} = \sum_{A \in \mathcal{S}} \frac{1}{\binom{n}{\lvert A\rvert}} \leq \frac{\lvert \mathcal{S}\rvert}{\binom{n}{\lfloor n/2\rfloor}}.\] And since the left-hand side is at most $1$ (the quantity we're taking the expectation of is always at most $1$), this means $\lvert \mathcal{S}\rvert \leq \binom{n}{\lfloor n/2\rfloor}$, as desired. </div> <h1 id="proof-of-the-main-theorem">Proof of the main theorem</h1> <p>Now we’re ready to prove <span class="crossref">Theorem 2</span>.</p> <p>First, we can assume that the $a_i$’s are all <em>positive</em>, as flipping the sign of some $a_i$ doesn’t affect the value of $\max_a \mathbb{P}[\varepsilon_1a_1 + \cdots + \varepsilon_na_n = a]$. One way to see this is that we could imagine choosing all the $\varepsilon_i$’s from \(\{-1, 1\}\) instead of \(\{0, 1\}\) — this wouldn’t affect $\max_a \mathbb{P}[\varepsilon_1a_1 + \cdots + \varepsilon_na_n = a]$, since it’d correspond to performing the transformation $a \mapsto 2a - \frac{1}{2}(a_1 + \cdots + a_n)$ to our random variable $\varepsilon_1a_1 + \cdots + \varepsilon_na_n$. And if we’re choosing \(\varepsilon_i \in \{-1, 1\}\), then clearly flipping the sign of $a_i$ has no effect on the distribution of this random variable.</p> <p>Now fix $a$, and define a collection $\mathcal{S}$ consisting of all the subsets of $[n]$ that correspond to subset sums of exactly $a$ — i.e., for each $(\varepsilon_1, \ldots, \varepsilon_n)$ satisfying $\varepsilon_1a_1 + \cdots + \varepsilon_na_n = a$, we place the corresponding set \(A = \{i \in [n] \mid \varepsilon_i = 1\}\) into $\mathcal{S}$.</p> <p>The key observation (and where Sperner’s theorem comes in) is the following.</p> <div class="claim"> The collection $\mathcal{S}$ is an antichain. </div> <div class="proof"> Assume for contradiction that there's two sets $A$ and $B$ in $\mathcal{S}$ with $A \subsetneq B$. This means they correspond to $(\varepsilon_1, \ldots, \varepsilon_n)$ and $(\varepsilon_1', \ldots, \varepsilon_n')$ such that $\varepsilon_i \leq \varepsilon_i'$ for all $i$, which means \[\varepsilon_1a_1 + \cdots + \varepsilon_na_n &lt; \varepsilon_1'a_1 + \cdots + \varepsilon_n'a_n.\] (If we're thinking about these quantities as subset sums of $\{a_1, \ldots, a_n\}$, then the point is that the subset sum corresponding to $B$ includes all the terms in the one corresponding to $A$, and at least one extra term; and since all the $a_i$'s are positive, this means its value must be strictly greater.) <br/><br/> But these sums are both supposed to be $a$ (by the definition of $\mathcal{S}$), so this is a contradiction. </div> <p>So then Sperner’s theorem implies that $\lvert \mathcal{S}\rvert \leq \binom{n}{\lfloor n/2\rfloor}$, which proves <span class="crossref">Theorem 2</span> (as there’s $2^n$ possible outcomes for $(\varepsilon_1, \ldots, \varepsilon_n)$, and the ‘good’ ones precisely correspond to elements of $\mathcal{S}$).</p>]]></content><author><name></name></author><category term="combinatorics"/><summary type="html"><![CDATA[A proof of Erd&#337;s's theorem that random sums of the form $\varepsilon_1a_1 + \cdots + \varepsilon_na_n$ (for random $\varepsilon_i \in \{0, 1\}$ and fixed $a_i$) cannot be too concentrated.]]></summary></entry><entry><title type="html">Setup of Interactive Proofs</title><link href="https://sanjanad1024.github.io/blog/2024/interactive-proofs/" rel="alternate" type="text/html" title="Setup of Interactive Proofs"/><published>2024-06-03T00:00:00+00:00</published><updated>2024-06-03T00:00:00+00:00</updated><id>https://sanjanad1024.github.io/blog/2024/interactive-proofs</id><content type="html" xml:base="https://sanjanad1024.github.io/blog/2024/interactive-proofs/"><![CDATA[<p>In this post, I’ll give an informal description of what interactive proofs are, and a few simple examples. The content of this post is based on lectures from the classes 18.404 (the lecture from December 7) and 18.405 (the lecture from April 11) at MIT. (This post is primarily setup for a few future posts on some really cool things we can do with interactive proofs.)</p> <p>We’ll first set up <em>deterministic</em> interactive proofs (to illustrate the model in a simpler setting, and to motivate what follows — in particular, why we need randomness); and then we’ll extend the model to <em>randomized</em> interactive proofs (which are what we’re really interested in).</p> <h1 id="deterministic-interactive-proofs">Deterministic interactive proofs</h1> <p>Imagine we’ve got a <span class="vocab">prover</span>, who we think of as all-powerful, and a <span class="vocab">verifier</span>, who we think of as computationally bounded. (This means we want the verifier to run in polynomial time; we don’t care how long the prover takes to run.)</p> <p>Imagine we’ve got a statement $x$, and the prover wants to convince the verifier that $x$ is true. To do so, the prover looks at $x$ and sends the verifier some message $m_1$. And then the verifier looks at $x$ and $m_1$, and sends the prover some message $m_2$. And then the prover looks at $x$, $m_1$, and $m_2$, and sends the prover some message $m_3$. And so on — the prover and verifier keep on talking back and forth, and eventually the verifier decides to <em>accept</em> (meaning they believe the prover and agree $x$ is true) or <em>reject</em> (meaning they don’t believe the prover and think $x$ is false).</p> <center><img src="/assets/img/ipsat1.png" width="400" height="auto"/></center> <p>Note that since the verifier is supposed to run in $\textsf{poly}(\lvert x\rvert)$ time, the number of messages and the length of each message should be $\textsf{poly}(\lvert x\rvert)$.</p> <div class="question"> What kinds of statements can the prover convince the verifier of? Or in other words, what kinds of problems can we 'solve' using such a proof system? </div> <p>To formalize this, we need to define what it means to solve a problem using such a proof system. Imagine we’ve got a decision problem, which we can think of as a function \(f \colon \{0, 1\}^\ast \to \{0, 1\}\) (where we encode the input $x$ as a bit-string, and $f(x)$ is $1$ if $x$ is a $\textsf{YES}$ instance to the decision problem and $0$ if $x$ is a $\textsf{NO}$ instance) — so here the statement the prover is trying to convince the verifier of is that $f(x) = 1$.</p> <p>What should it mean for an interactive proof to ‘solve’ $f$? When we talk about an interactive proof solving $f$, we’re going to say essentially that there is a <em>verifier</em> who can be convinced of true statements of the form $f(x) = 1$, but not false ones. So on one hand, whenever $f(x) = 1$, there should be a <span class="vocab">good prover</span> that successfully convinces the verifier that $f(x) = 1$ (because this is true). On the other hand, when $f(x) = 0$, no <span class="vocab">cheating prover</span> should be able to convince the verifier that $f(x) = 1$ (because this is false) — so no matter what the prover tries to do, the verifier should reject.</p> <div class="definition"> We say $f$ <span class="vocab">has a deterministic interactive proof</span> if there is a verifier such that: <ul> <li> <span class="vocab">(Correctness)</span> For each $x$ such that $f(x) = 1$, there exists a prover that makes the verifier accept. </li> <li> <span class="vocab">(Soundness)</span> For each $x$ such that $f(x) = 0$, there does <em>not</em> exist a prover that makes the verifier accept (i.e., <em>every</em> possible prover causes the verifier to reject). </li> </ul> </div> <p>In other words, true statements of the form $f(x) = 1$ should have good proofs (that the verifier accepts), and false statements should not.</p> <div class="definition"> We define $\textsf{DIP}$ as the class of decision problems which have a deterministic interactive proof. </div> <h2 id="an-example--textsfsat">An example — $\textsf{SAT}$</h2> <p>To illustrate this definition, here’s an example of a deterministic interactive proof for $\textsf{SAT}$ — the problem where we’re given a Boolean formula $\varphi$, and we want to figure out whether it’s satisfiable or not.</p> <div class="definition"> We define $\textsf{SAT}$ as the following decision problem: <ul> <li> <b>Input:</b> a Boolean formula $\varphi$ (in some collection of variables $x_1$, $\ldots$, $x_n$, and with the operations $\wedge$, $\vee$, and $\neg$, which denote $\textsf{AND}$, $\textsf{OR}$, and $\textsf{NOT}$). </li> <li> <b>Decide:</b> whether there exists a <span class="vocab">satisfying assignment</span> to $\varphi$ &mdash; i.e., an assignment of values $a_1$, $\ldots$, $a_n$ to the variables (with $a_i \in \{\texttt{T}, \texttt{F}\}$ for each $i$) such that plugging them in makes $\varphi$ evaluate to $\texttt{T}$. </li> </ul> </div> <p>(In the notation where we think of decision problems as functions \(\{0, 1\}^\ast \to \{0, 1\}\), we’d say that $\textsf{SAT}(\varphi)$ is $1$ if $\varphi$ is satisfiable and $0$ if not; we think of $\varphi$ as being encoded as a bit-string in some reasonable way.)</p> <div class="example"> The problem $\textsf{SAT}$ has a deterministic interactive proof, where the verifier and good prover (for $\textsf{YES}$ instances) are defined as follows. On input $\varphi$: <ul> <li> The good prover finds a satisfying assignment to $\varphi$ and sends it to the verifier. </li> <li> The verifier plugs the assignment it receives into $\varphi$ and checks that it really is a satisfying assignment (and <span class="vocab">accepts</span> if yes and <span class="vocab">rejects</span> if no). </li> </ul> </div> <p>Note that we don’t need to care how long it takes the <em>prover</em> to come up with the satisfying assignment; what’s important is that the <em>verifier</em> can check that it’s really a satisfying assignment in polynomial time.</p> <p>This protocol satisfies correctness — if $\varphi$ is satisfiable, then the good prover will make the verifier accept. It also satisfies soundness — if $\varphi$ is <em>not</em> satisfiable, then no matter what assignment the cheating prover sends, when the verifier plugs it in, they’ll find that it’s not a satisfying assignment (because <em>no</em> assignment is), and so they’ll reject.</p> <h2 id="textsfdip--textsfnp">$\textsf{DIP} = \textsf{NP}$</h2> <p>Note that the protocol we gave for $\textsf{SAT}$ doesn’t involve any interaction at all — the prover just sends one message, and the verifier just looks at it and decides to accept or reject. In fact, this type of protocol corresponds exactly to the class $\textsf{NP}$. To see this, one way of defining $\textsf{NP}$ is as the class of problems with <span class="vocab">efficiently verifiable certificates</span>.</p> <div class="definition"> We define $\textsf{NP}$ as the class of decision problems $f$ such that there exists a polynomial-time algorithm $\mathcal{V}$ such that for all $x$, we have \[f(x) = 1 \iff (\exists \, y \text{ of length } \textsf{poly}(\lvert x\rvert))[\mathcal{V}(x, y) \text{ accepts}].\] </div> <p>In words, we think of $\mathcal{V}$ as a <span class="vocab">$\textsf{NP}$-verifier</span> for $f$ — it’s an efficient algorithm that takes in both our input $x$ and a polynomial-length <span class="vocab">certificate</span> $y$, and checks that $y$ is a ‘good certificate’ for $x$. And $\textsf{YES}$ instances $x$ should have good certificates (i.e., when $f(x) = 1$ there should exist a good certificate $y$), while $\textsf{NO}$ instances should <em>not</em> have good certificates.</p> <div class="example"> We have $\textsf{SAT} \in \textsf{NP}$ &mdash; we can define a 'good certificate' for $\varphi$ to be a satisfying assignment to $\varphi$ (we can construct a $\textsf{NP}$-verifier $\mathcal{V}$ which checks whether some assignment is a good certificate for $\varphi$ by simply plugging it in; and by definition $\varphi$ is a $\textsf{YES}$ instance to $\textsf{SAT}$ if and only if there exists a satisfying assignment, i.e., a good certificate for $\varphi$). </div> <p>In this definition, we can think of $\textsf{NP}$ as the class of problems $f$ which have a deterministic interactive proof with no interaction — the prover just sends a single message, and the verifier decides to accept or reject. (As in <span class="crossref">Example 5</span>, we define the good prover to send over a good certificate for the input $x$, and the verifier to check that the certificate it received really works — in particular, the verifier for the interactive proof is exactly the $\textsf{NP}$-verifier $\mathcal{V}$.) In particular, this immediately means $\textsf{NP} \subseteq \textsf{DIP}$ (as $\textsf{NP}$ is a special case of $\textsf{DIP}$).</p> <p>Our definition of deterministic interactive proofs allows for interaction, so we might hope that it makes the proof system more powerful. Unfortunately, this is false — it turns out that even <em>with</em> interaction, we can’t use such protocols to solve any problems other than the ones already in $\textsf{NP}$ (which we could have solved even without interaction).</p> <div class="theorem"> We have $\textsf{DIP} = \textsf{NP}$. </div> <div class="proof"> We've already seen that $\textsf{NP} \subseteq \textsf{DIP}$, so it remains to show that $\textsf{DIP} \subseteq \textsf{NP}$. Suppose $f \in \textsf{DIP}$, so we've got some deterministic interactive proof for $f$ &mdash; this means the prover and verifier talk back and forth, and eventually the verifier decides to accept or reject. Our goal is to remove the interaction from this protocol &mdash; i.e., to turn it into one where the prover sends a single message, and the verifier just decides whether to accept or reject. (This is because non-interactive deterministic interactive proofs correspond exactly to $\textsf{NP}$, as seen above.) <br/><br/> The idea is that because the verifier is deterministic, given the input $x$, the prover can know exactly what the entire interaction will look like &mdash; they know they're going to send a message $m_1$; then they can look at $x$ and $m_1$ and figure out exactly what message $m_2$ the verifier is going to send; then they can look at $x$, $m_1$, and $m_2$ and figure out exactly what message $m_3$ they'd respond with; and so on. <br/><br/> And this means the prover can just send the verifier their <em>entire</em> end of the interaction all in one message &mdash; i.e., the prover sends the verifier $(m_1, m_3, \ldots)$. And the verifier then simulates the interaction by themselves, plugging in these messages for the prover's end of the interaction &mdash; they look at $x$, imagine that the prover sends them $m_1$ and figure out what message $m_2$ they'd respond with, imagine that the prover then sends them $m_3$ and figure out what message $m_4$ they'd respond with, and so on; and in the end, they see whether they'd accept or reject (and they make the same decision here). <br/><br/> If $f(x) = 1$, then there's some good prover for the original protocol that makes the original verifier accept; so if we take $(m_1, m_3, \ldots)$ to correspond to that good prover, then the new verifier will accept as well (since it's just simulating the original verifier's interaction with that good prover). Meanwhile, if $f(x) = 0$, then every cheating prover for the original protocol makes the original verifier reject, so no matter what list of messages $(m_1, m_3, \ldots)$ the new cheating prover sends, the new verifier will reject as well (since it'll be simulating the original verifier's interaction with some cheating prover). </div> <h1 id="randomized-interactive-proofs">Randomized interactive proofs</h1> <p>We’ve seen that with deterministic interactive proofs, we don’t get anything out of interaction — in other words, any deterministic interactive proof that involves interaction can be turned into one that doesn’t (which means $\textsf{DIP} = \textsf{NP}$). And the reason for this was essentially that if the verifier is deterministic, then the prover can predict in advance <em>everything</em> that the verifier is going to say, so they can just have all their responses ready and send them all at once.</p> <p>We don’t like this — our hope is to define a reasonable model of interactive proofs that <em>increases</em> the class of problems we could solve. And the way we’re going to do this is by allowing the verifier to be <em>randomized</em> — this means the verifier gets to toss some coins when it’s choosing its message. So the prover looks at the input $x$ and sends a message $m_1$, as before. And then the verifier looks at $x$ and $m_1$ <em>and tosses some coins</em> to come up with a message $m_2$ to respond with. And then the prover looks at $x$, $m_1$, and $m_2$ to come up with a message $m_3$, and the verifier looks at $x$, $m_1$, $m_2$, and $m_3$ and tosses some more coins to come up with a message $m_4$, and so on; and in the end the verifier either accepts or rejects.</p> <center><img src="/assets/img/ipsat2.png" width="400" height="auto"/></center> <p>(In this picture, $r_i$ denotes the randomness the verifier uses at each step — i.e., the outcomes of the $i$th set of coin tosses.)</p> <div class="remark"> We're using a <span class="vocab">private-coin model</span>, where the prover doesn't get to see the outcomes of the verifier's coin tosses. But you could also imagine a <span class="vocab">public-coin model</span>, where the prover <em>does</em> get to see these outcomes. Of course, any public-coin interactive proof can be made into a private-coin one (where we have the verifier simply announce the outcomes of their coin tosses together with the corresponding message). Quite surprisingly, it turns out that the converse is true as well &mdash; any private-coin protocol can also be made into a public-coin one! This is a very nice <a href="https://www.cs.toronto.edu/tss/files/papers/goldwasser-Sipser.pdf" target="_blank">result</a> of Goldwasser and Sipser (1986). <br/><br/> I'm probably not going to write more about the public-coin model; the protocol for graph non-isomorphism we'll see in this post will rely quite crucially on the fact that the prover doesn't see the verifier's coins (it can be converted to a public-coin protocol by the result of Goldwasser&ndash;Sipser, but this isn't obvious); but the protocols we'll see in future posts won't be (i.e., they can directly be viewed as public-coin protocols as well). </div> <p>We now need to define what it means for a randomized interactive proof to solve a decision problem $f$. This will be very similar to the definition for deterministic interactive proofs, but now that we’ve got randomness, we need to allow some probability of error (otherwise the randomness wouldn’t have any point).</p> <div class="definition"> We say $f$ <span class="vocab">has an interactive proof</span> if there is a verifier such that: <ul> <li> <span class="vocab">(Correctness)</span> For each $x$ such that $f(x) = 1$, there exists a prover that makes the verifier accept with probability at least $\frac{2}{3}$. </li> <li> <span class="vocab">(Soundness)</span> For each $x$ such that $f(x) = 0$, for every possible prover, the probability that the verifier accepts is at most $\frac{1}{3}$. </li> </ul> </div> <p>There’s a few decisions we’ve made with these definitions that aren’t obvious (i.e., it’d have been reasonable to do the opposite) but turn out not to matter:</p> <ul> <li> The values of $\frac{2}{3}$ (which we call the <span class="vocab">correctness parameter</span>) and $\frac{1}{3}$ (the <span class="vocab">soundness parameter</span>) are arbitrary &mdash; if we've got a protocol with these parameters, then we can get one with correctness parameter $1 - \frac{1}{2^k}$ and soundness parameter $\frac{1}{2^k}$ by simply running $\textsf{poly}(k)$ independent trials of the original one (and taking their majority outcome). </li> <li> We're allowing error in both the cases $f(x) = 0$ and $f(x) = 1$. But we could imagine instead allowing error in only one of the cases &mdash; we say a protocol has <span class="vocab">perfect correctness</span> if it only has error in the case $f(x) = 0$ (i.e., when $f(x) = 1$, there's a prover that makes the verifier <em>always</em> accept). <br/><br/> It turns out that any interactive proof protocol can be converted to one with perfect correctness; this is not obvious and is also a very nice result, though I'm not sure who it's due to. All the protocols we'll discuss will have perfect correctness. <br/><br/> (On the other hand, the error in soundness <em>is</em> necessary &mdash; it's <em>not</em> true that we can convert any protocol to one with perfect soundness.) </li> <li> We've made the <em>verifier</em> randomized, but we're still keeping the <em>prover</em> deterministic. We could imagine allowing the prover to be randomized as well, but this wouldn't increase the power of the system &mdash; the prover is computationally unbounded, so we can without loss of generality assume that the prover always (deterministically) chooses the response that maximizes the probability of the verifier accepting. </li> </ul> <h2 id="an-example--graph-non-isomorphism">An example — graph non-isomorphism</h2> <p>We first considered the model of <em>deterministic</em> interactive proofs, and we saw that the only problems we can solve using them are the problems in $\textsf{NP}$ (for which we don’t even need the interaction). So the first thing we might wonder is, does this new model of <em>randomized</em> interactive proofs, have the same issue, or does it actually allow us to solve new problems?</p> <p>So the first thing we’ll see is an example of an interactive proof for a problem that we don’t know to be in $\textsf{NP}$ — the problem of determining whether two graphs are <em>non</em>-isomorphic.</p> <div class="definition"> Two graphs $G_1$ and $G_2$ are <span class="vocab">isomorphic</span> if there's a way to permute the vertices of $G_1$ that turns it into $G_2$ &mdash; i.e., a permutation $\pi \colon V(G_1) \to V(G_2)$ such that $\{u, v\}$ is an edge in $G_1$ if and only if $\{\pi(u), \pi(v)\}$ is an edge in $G_2$. </div> <div class="definition"> We define $\textsf{GNI}$ as the following decision problem: <ul> <li> <b>Input:</b> two graphs $G_1$ and $G_2$ (with the same number of vertices). </li> <li> <b>Decide:</b> whether $G_1$ and $G_2$ are <em>non</em>-isomorphic. </li> </ul> </div> <p>Written as a function \(\{0, 1\}^\ast \to \{0, 1\}\), we’d say that $\textsf{GNI}(G_1, G_2)$ is $1$ if $G_1$ and $G_2$ are non-isomorphic, and $0$ if they are isomorphic.</p> <p>The opposite problem $\textsf{GI}$, of determining whether two given graphs $G_1$ and $G_2$ <em>are</em> isomorphic, is in $\textsf{NP}$ — we can take the certificate to simply be the permutation $\pi \colon V(G_1) \to V(G_2)$ that turns $G_1$ into $G_2$. This in particular means $\textsf{GI}$ has an interactive proof (that doesn’t involve any interaction), as with all problems in $\textsf{NP}$.</p> <p>But it <em>isn’t</em> clear whether $\textsf{GNI}$ is in $\textsf{NP}$ — there’s a simple certificate showing that two graphs <em>are</em> isomorphic, but we don’t know of a certificate showing that they’re <em>not</em> isomorphic.</p> <p>Still, it turns out that $\textsf{GNI}$ <em>does</em> have a (randomized) interactive proof!</p> <div class="example"> The problem $\textsf{GNI}$ has an interactive proof &mdash; on input $(G_1, G_2)$: <ul> <li> The verifier chooses $i \in \{1, 2\}$ uniformly at random and permutes the vertices of $G_i$ uniformly at random to produce a new graph $H$. </li> <li> The verifier sends the prover $H$ and asks them which of $G_1$ and $G_2$ it came from (i.e., what the value of $i$ is). They <span class="vocab">accept</span> if the prover answers correctly and <span class="vocab">reject</span> if not. </li> </ul> </div> <div class="proof"> If $G_1$ and $G_2$ are indeed non-isomorphic, then there's a good prover who'll always be able to answer correctly &mdash; $H$ must be isomorphic to the graph $G_i$ that the verifier chose (by construction), and it can't be isomorphic to the other one (because if it were isomorphic to both, then $G_1$ and $G_2$ are isomorphic). So the prover can simply recover $i$ by checking which of $G_1$ and $G_2$ it's isomorphic to. <br/><br/> Meanwhile, if $G_1$ and $G_2$ are isomorphic, then the graph $H$ that the prover sees has nothing to do with $i$ (i.e., it has the same distribution whether $i$ is $1$ or $2$ &mdash; either way, it's a uniform random element of their isomorphism class). So no matter what the cheating prover tries to do, they're essentially being asked to predict a random coin toss with no useful information, which means they'll only have a $\frac{1}{2}$ chance of being correct. </div> <h2 id="the-class-textsfip">The class $\textsf{IP}$</h2> <p>The example of an interactive proof for $\textsf{GNI}$ shows that adding randomness to our model has done <em>something</em> nontrivial — it’s allowed us to solve at least one problem that we wouldn’t have known how to solve without it. So that’s good news; but now we’d like to get a better understanding of <em>how</em> much more we can now solve.</p> <div class="definition"> We define $\textsf{IP}$ as the class of decision problems $f$ which have an interactive proof. </div> <div class="question"> How powerful is $\textsf{IP}$? </div> <p>It turns out, quite surprisingly, that $\textsf{IP}$ is <em>extremely</em> powerful!</p> <div class="theorem" text="Shamir 1990"> We have $\textsf{IP} = \textsf{PSPACE}$. </div> <p>(The class $\textsf{PSPACE}$ is defined as the class of problems which can be solved in polynomial <em>space</em>.)</p> <p>This is quite amazing — for example, it means that there’s an interactive proof that a Boolean formula is <em>not</em> satisfiable (which is already quite non-obvious), as well as lots of problems that look much harder.</p> <p>One direction of <span class="crossref">Theorem 16</span>, that $\textsf{IP} \subseteq \textsf{PSPACE}$, isn’t too difficult — the idea is that if we start with some interactive proof for some decision problem $f$, then by carefully going through all possible messages the prover and verifier could send, we can calculate the probability that the ‘optimal prover’ makes the verifier accept; and we can do this only using polynomial space. Here are the details of this argument.</p> <div class="lemma"> We have $\textsf{IP} \subseteq \textsf{PSPACE}$. </div> <div class="proof"> Suppose that $f \in \textsf{IP}$, so it has some verifier as in the definition of $\textsf{IP}$. Then in order to decide $f$ on an input $x$, our goal is to calculate the maximum (over all possible provers) of the probability (over the verifier's internal randomness) that the verifier accepts &mdash; because we know this probability is at least $\frac{2}{3}$ if $f(x) = 1$ (by correctness) and at most $\frac{1}{3}$ if $f(x) = 0$ (by soundness). <br/><br/> To do so, suppose the protocol runs for $k$ rounds (where $k = \textsf{poly}(\lvert x\rvert)$). Then for each $0 \leq i \leq k$, we'll define $\textsf{Prob}_i(x, m_1, \ldots, m_i)$ as the maximum (over all possible provers) probability that the verifier accepts if we start up the protocol from the end of the $i$th round pretending that these messages have already occurred (i.e., we imagine that the prover has already sent $m_1$, the verifier has already responded with $m_2$, and so on up to $m_i$; and now we're starting the protocol up from the end of the $i$th round, and we want to think about how it continues). Then our goal is to compute $\textsf{Prob}_0(x)$. <br/><br/> We'll compute these quantities recursively &mdash; suppose we're trying to compute $\textsf{Prob}_{i - 1}(x, m_1, \ldots, m_{i - 1})$. Then we consider what happens on the $i$th round. If $i$ is odd, meaning that the prover speaks, then since we're trying to take a <em>maximum</em> over all possible provers (i.e., we want to consider the <em>best</em> possible message $m_i$ for the prover to send), we have \[\textsf{Prob}_{i - 1}(x, m_1, \ldots, m_{i - 1}) = \max_{m_i}\textsf{Prob}_i(x, m_1, \ldots, m_i).\] Meanwhile, if $i$ is even, meaning that the verifier speaks, then we want to consider the <em>distribution</em> (over the verifier's internal randomness) of the message $m_i$ it sends (given the previous messages), and compute the appropriate weighted average of the acceptance probabilities of the remainder of the protocol, so \[\textsf{Prob}_{i - 1}(x, m_1, \ldots, m_{i - 1}) = \sum_i \mathbb{P}[\text{verifier sends $m_i$}]\cdot \textsf{Prob}_{i - 1}(x, m_1, \ldots, m_i).\] This gives a recursion that we can compute in polynomial space &mdash; we start with $i = 0$, then iterate over all messages $m_1$ one at a time, then iterate over all messages $m_2$ one at a time (for each $m_1$), and so on. At every layer of the recursion, we essentially only need to store the current message $m_i$ we're trying, as well as our current computation for the maximum or sum (note that the quantities $\mathbb{P}[\text{verifier sends $m_i$}]$ can be computed in polynomial space as well, simply by iterating over all possible outcomes of the verifier's coin tosses one at a time and running the verifier with each). <br/><br/> So we can use this recursion to compute $\textsf{Prob}_0(x)$ in polynomial space, which lets us solve $f$. </div> <p>So the direction that $\textsf{IP} \subseteq \textsf{PSPACE}$ is not too hard. On the other hand, the direction that $\textsf{PSPACE} \subseteq \textsf{IP}$ — that every problem which can be solved in polynomial <em>space</em> in fact has an interactive proof where the verifier runs in polynomial <em>time</em> — is much more surprising, and the proof involves several very cool ideas. I’ll explain the proof in future posts.</p>]]></content><author><name></name></author><category term="complexity,"/><category term="TCS"/><summary type="html"><![CDATA[An informal description of how interactive proofs work and a few examples.]]></summary></entry><entry><title type="html">Adjoint of a Compact Operator</title><link href="https://sanjanad1024.github.io/blog/2024/adjoint-compact/" rel="alternate" type="text/html" title="Adjoint of a Compact Operator"/><published>2024-06-02T00:00:00+00:00</published><updated>2024-06-02T00:00:00+00:00</updated><id>https://sanjanad1024.github.io/blog/2024/adjoint-compact</id><content type="html" xml:base="https://sanjanad1024.github.io/blog/2024/adjoint-compact/"><![CDATA[<p>While studying for the 18.102 (Introduction to Functional Analysis) final this semester, I came across the following theorem, which I think is quite cool (see below for the relevant definitions).</p> <div class="theorem"> Let $X$ and $Y$ be Banach spaces, and suppose that $T \colon X \to Y$ is a compact bounded linear operator. Then its adjoint $T^* \colon Y^* \to X^*$ is also compact. </div> <p>In this post, I’ll explain a proof, based on the first answer to this <a href="https://math.stackexchange.com/questions/41432/easy-proof-adjointcompact-compact" target="_blank">Math StackExchange post</a>.</p> <h1 id="definitions-and-setup">Definitions and setup</h1> <p>First, here are some preliminary definitions (stated here for reference). Throughout this post, we work over $\mathbb{C}$.</p> <ul> <li> <div class="sd-hidden" desc="Normed linear spaces and Banach spaces"> <div class="definition"> We say $X$ is a <span class="vocab">normed linear space</span> if $X$ is a vector space together with a norm $\lVert \bullet \rVert$ satisfying the following three properties: <ul> <li> $\lVert x \rVert \geq 0$ for all $x \in X$, with equality if and only if $x = 0$.</li> <li> Homogeneity &mdash; $\lVert \alpha x\rVert = \lvert \alpha \rvert \lVert x\rVert$ for all $x \in X$ and $\alpha \in \mathbb{C}$. </li> <li> The triangle inequality &mdash; $\lVert x + y \rVert \leq \lVert x \rVert + \lVert y \rVert$ for all $x, y \in X$. </li> </ul> </div> <div class="definition"> A <span class="vocab">Banach space</span> is a complete normed linear space. </div> If $X$ is a normed linear space, then the norm induces a metric $d(x, y) = \lVert x - y\rVert$. When we say that $X$ is complete, we're referring to this norm. </div> </li> <li> <div class="sd-hidden" desc="Bounded linear operators"> Next, we'll state a few definitions regarding linear operators between normed linear spaces. <div class="definition"> If $X$ and $Y$ are normed linear spaces and $T \colon X \to Y$ is a linear operator, we say $T$ is <span class="vocab">bounded</span> if there exists a constant $c$ such that $\lVert Tx\rVert \leq c\lVert x\rVert$ for all $x \in X$. </div> <div class="definition"> If $T$ is a bounded linear operator, we define its <span class="vocab">operator norm</span> as \[\lVert T\rVert = \sup_{x \neq 0} \frac{\lVert Tx\rVert}{\lVert x\rVert}.\] </div> By homogeneity, we could equivalently define $\lVert T\rVert$ as $\sup_{\lVert x\rVert = 1} \lVert Tx\rVert$. <div class="fact"> If $X$ and $Y$ are normed linear spaces, then the set of bounded linear operators $T \colon X \to Y$ form a normed linear space as well (under the operator norm), which we denote by $\mathcal{B}(X, Y)$. Furthermore, if $Y$ is Banach, then so is $\mathcal{B}(X, Y)$. </div> </div> </li> <li> <div class="sd-hidden" desc="Dual spaces and adjoints"> <div class="definition"> For a normed linear space $X$, its <span class="vocab">dual space</span> $X^\ast$ is defined as $\mathcal{B}(X, \mathbb{C})$. We refer to elements of $X^\ast$ (which are bounded linear functions $f \colon X \to \mathbb{C}$) as <span class="vocab">functionals</span>. </div> Note that since $\mathbb{C}$ is Banach (i.e., complete), so is $X^*$ (for any normed linear space $X$). <div class="definition"> For any bounded linear operator $T \colon X \to Y$, we define its <span class="vocab">adjoint operator</span> $T^* \colon Y^* \to X^*$ as the map such that $(T^\ast g)(x) = g(Tx)$ for all $g \in Y^\ast$ and $x \in X$. </div> In other words, we're defining $T^\ast$ as the map sending each bounded linear operator $g \colon Y \to \mathbb{C}$ (which is an element of $Y^\ast$) to the bounded linear operator $g \circ T \colon X \to \mathbb{C}$ (an element of $X^\ast$). <div class="fact"> If $T$ is a bounded linear operator, then so is $T^\ast$. </div> </div> </li> <li> <div class="sd-hidden" desc="Compactness in metric spaces"> <div class="definition"> For a metric space $X$, we say a subset $M \subseteq X$ is <span class="vocab">compact</span> if every open cover of $M$ has a finite subcover &mdash; in other words, for any collection $\mathcal{U}$ of open sets whose union contains $M$, we can find a <em>finite</em> subcollection of $\mathcal{U}$ whose union still contains $M$. </div> <div class="definition"> For a metric space $X$, we say a subset $M \subseteq X$ is <span class="vocab">sequentially compact</span> if every sequence $(x_n) \subseteq M$ has a subsequence converging to some point in $M$. </div> <div class="fact"> Compactness and sequential compactness are equivalent (for metric spaces). </div> The reason there's two separate terms is because both can be defined in greater generality for general topological spaces, and there they're not necessarily equivalent. In this post, we'll make use of both notions. </div> </li> </ul> <p>The main focus of this post is a result about compact operators, so now we’ll discuss what it means for an operator to be compact. (We’ll only consider the case where we’re working with bounded linear operators between two Banach spaces.)</p> <div class="definition"> For Banach spaces $X$ and $Y$, we say a bounded linear operator $T \colon X \to Y$ is <span class="vocab">compact</span> if for every bounded sequence $(x_n) \subseteq X$, its image $(Tx_n) \subseteq Y$ has a convergent subsequence. </div> <p>There’s an equivalent characterization of when an operator is compact, which may make it more clear where the name comes from. (In the post, we’re going to make use of both characterizations.)</p> <div class="lemma"> For Banach spaces $X$ and $Y$, an operator $T \colon X \to Y$ is compact if and only if for every bounded subset $M \subseteq X$, its image $TM \subseteq Y$ has compact closure. </div> <p>We’ll use $\operatorname{Cl}(M)$ to refer to the closure of a subset $M$, so the condition here states that $\operatorname{Cl}(TM) \subseteq Y$ is compact (as a metric space) whenever $M \subseteq X$ is bounded. We’ll refer to this condition as $(\star)$.</p> <div class="proof"> First, the backwards direction is pretty direct &mdash; suppose that $T$ has the property $(\star)$. Consider some bounded sequence $(x_n) \subseteq X$, and let $M = \{x_n \mid n \in \mathbb{N}\}$ be the set it forms (so that $M$ is bounded). Then $(Tx_n)$ is contained in $\operatorname{Cl}(TM)$, which is compact by $(\star)$; so it must have a convergent subsequence. <br/><br/> Now we'll prove the forwards direction &mdash; we'll suppose that $T$ is compact (as in the original definition) and show that it satisfies $(\star)$. Fix some bounded set $M \subseteq X$. We want to show $\operatorname{Cl}(M)$ is compact, and we'll do so by showing that it's <em>sequentially</em> compact &mdash; i.e., that any $(y_n) \subseteq \operatorname{Cl}(TM)$ has a convergent subsequence whose limit is also in $\operatorname{Cl}(TM)$. <br/><br/> First, to apply the compactness of $T$, we really want to be working with a sequence in $TM$ rather than its closure, so the first step is to replace $(y_n) \subseteq \operatorname{Cl}(TM)$ with a sequence $(y_n') \subseteq TM$ that's 'close' to it &mdash; since $TM$ is dense in its closure, for each $n \in \mathbb{N}$ we can find some $y_n' \in TM$ with $\lVert y_n - y_n'\rVert &lt; \frac{1}{n}$, and since $y_n' \in TM$, we can find $x_n \in M$ with $y_n' = Tx_n$. <br/><br/> And now the sequence $(x_n)$ is bounded (as it's contained in $M$, which is bounded), so by the compactness of $T$, its image $(y_n') = (Tx_n) \subseteq Y$ must have a convergent subsequence. And since $\lVert y_n - y_n'\rVert \to 0$ (as $n \to \infty$), this means the corresponding subsequence of $(y_n)$ is convergent as well. <br/><br/> Finally, we've found a subsequence of $(y_n)$ that converges to <em>some</em> point $y \in Y$. But since $\operatorname{Cl}(TM)$ is closed and each $y_n$ is in $\operatorname{Cl}(TM)$, this means $y \in \operatorname{Cl}(TM)$ as well. This proves that $\operatorname{Cl}(TM)$ is sequentially compact (and therefore compact), so we're done. </div> <h1 id="the-proof">The proof</h1> <p>We’ll now prove the main theorem. Suppose that $T \colon X \to Y$ is compact. Our goal is to show that $T^\ast \colon Y^\ast \to X^\ast$ is compact as well; using the definition of a compact operator, this means we’ve got some bounded sequence $(g_n) \subseteq Y^\ast$, and we want to show that $(T^\ast g_n) \subseteq X^\ast$ has a convergent subsequence.</p> <h2 id="step-1--reformulating-the-conclusion">Step 1 — reformulating the conclusion</h2> <p>First, we’re going to find a sufficient condition for a sequence $(T^\ast g_n) \subseteq X^\ast$ to be convergent that’s more convenient to work with (and we’re going to find a subsequence satisfying this property instead).</p> <div class="claim"> Let $B = \{x \in X \mid \lVert x\rVert \leq 1\}$ be the closed unit ball in $X$, and let $K = \operatorname{Cl}(TB)$ be the closure of its image in $Y$. Suppose that $(g_n) \subseteq Y^\ast$ is a sequence of functionals such that for every $\varepsilon &gt; 0$, there exists $N$ such that for all $m, n \geq N$ we have \[\sup_{y \in K} \lvert g_m(y) - g_n(y)\rvert \leq \varepsilon.\] Then the sequence $(T^\ast g_n) \subseteq X^\ast$ is convergent. </div> <div class="proof"> First, it's enough to show that $(T^\ast g_n)$ is <em>Cauchy</em> &mdash; this automatically implies it's convergent, as $X^\ast$ is complete. So we want to show that for every $\varepsilon &gt; 0$, there exists $N$ such that for all $m, n \geq N$ we have $\lVert T^\ast g_m - T^\ast g_n\rVert \leq \varepsilon$. But for any functional $g$, we have \[\lVert T^\ast g\rVert = \sup_{\lVert x\rVert = 1} \lvert (T^\ast g)(x)\rvert = \sup_{\lVert x\rVert = 1} \lvert g(Tx)\rvert \leq \sup_{y \in K} \lvert g(y)\rvert\] (since if $\lVert x\rVert = 1$, then $Tx \in TB \subseteq K$). Taking $g = g_m - g_n$, we get \[\lVert T^\ast g_m - T^\ast g_n\rVert \leq \sup_{y \in K} \lvert g_m(y) - g_n(y)\rvert\] for all $m$ and $n$; so if we know the right-hand side is at most $\varepsilon$ for all $m, n \geq N$, then so is the left-hand side (with the same value of $N$). </div> <p>Note that $K$ is compact (because $T$ is compact, and $B \subseteq X$ is bounded) — this is the one place where we’re going to use the compactness of $T$. (After this, $T$ will basically disappear from the picture.)</p> <h2 id="step-2--finding-a-sequence-of-representatives">Step 2 — finding a sequence of representatives</h2> <p>Now our goal is to find a subsequence $(g_n’) \subseteq (g_n)$ satisfying the condition of <span class="crossref">Claim 4</span>. The first step towards doing so is finding a countable sequence of ‘representatives’ $y_1$, $y_2$, $\ldots$ for $K$ with certain nice properties. The reason for this is that we’re then going to construct our subsequence $(g_n’) \subseteq (g_n)$ such that it converges pointwise at each of these representatives $y_i$, and argue that this implies the desired conclusion.</p> <div class="claim"> There exists a sequence $(y_i) \subseteq K$ with the property that for every $\varepsilon &gt; 0$, there exists $N$ such that every $y \in K$ is within $\varepsilon$ of one of $y_1$, $\ldots$, $y_N$. </div> <div class="proof"> First, the compactness of $K$ implies that for every $n \in \mathbb{N}$, we can cover $K$ with a finite number of balls of radius $\frac{1}{n}$ &mdash; i.e., there exists a finite set of points $S_n \subseteq K$ such that $\bigcup_{y \in S_n} \mathbb{B}(z, \frac{1}{n}) \supseteq K$. (This is because the balls $\mathbb{B}(y, \frac{1}{n})$ over <em>all</em> points $y \in K$ form an open cover of $K$, and by the compactness of $K$, this open cover must have a finite subcover.) <br/><br/> Then we can take $(y_i)$ to consist of the points in $S_1$, then $S_2$, then $S_3$, and so on (in that order). <br/><br/> <center><img src="/assets/img/compact3.png" width="600" height="auto"/></center> <br/><br/> This will have the desired property &mdash; given any $\varepsilon &gt; 0$, we can fix $n \in \mathbb{N}$ such that $\frac{1}{n} \leq \varepsilon$. Then every $y \in K$ is within $\varepsilon$ of some point in $S_n$, so we can take $N = \lvert S_1\rvert + \cdots + \lvert S_n\rvert$. </div> <h2 id="step-3--defining-the-subsequence">Step 3 — defining the subsequence</h2> <p>Now we’re going to define our subsequence $(g_n’) \subseteq (g_n)$, so that it has the following property.</p> <div class="lemma"> There is a subsequence $(g_n') \subseteq (g_n)$ such that for each $i \in \mathbb{N}$, the sequence $(g_n'(y_i)) \subseteq \mathbb{C}$ is convergent (as $n \to \infty$). </div> <div class="proof"> We're going to use a diagonalization argument &mdash; the idea is that we'll first restrict to a subsequence along which $(g_n(y_1))$ converges, then further restrict to a subsequence along which $(g_n(y_2))$ converges, and so on; and in the end, we'll take the 'diagonal' of all these subsequences. <br/><br/> First, we know the sequence $(g_n)$ is bounded (by assumption), so there's some $c$ such that $\lVert g_n\rVert \leq c$ for all $n \in \mathbb{N}$. This means $\lvert g_n(y_1)\rvert \leq c\lVert y_1\rVert$ for all $n$, so the sequence $(g_n(y_1))$ is a bounded sequence in $\mathbb{C}$, which means it has a convergent subsequence (as it's a sequence in a compact subset of $\mathbb{C}$). So we can define a subsequence $(g_{n1}) \subseteq (g_n)$ such that $(g_{n1}(y_1))$ is convergent. <br/><br/> Next, we're going to further restrict this subsequence to deal with $y_2$ &mdash; we have $\lvert g_{n1}(y_2)\rvert \leq c\lVert y_2\rVert$ for all $n$, so the sequence $(g_{n1}(y_2))$ is also a bounded sequence in $\mathbb{C}$, which means it also has a convergent subsequence. So we can define a subsequence $(g_{n2}) \subseteq (g_{n1})$ such that $(g_{n2}(y_2))$ is convergent. <br/><br/> And we can continue doing this to get a nested list of subsequences $(g_n) \supseteq (g_{n1}) \supseteq (g_{n2}) \supseteq \cdots$ such that for each fixed $i \in \mathbb{N}$, the sequence $(g_{ni}(y_i)) \subseteq \mathbb{C}$ is convergent. <br/><br/> <center><img src="/assets/img/compact1.png" width="600" height="auto"/></center> <br/><br/> Finally, we define the subsequence $(g_n')$ by $g_n' = g_{nn}$ for each $n \in \mathbb{N}$ &mdash; so we're essentially taking the 'diagonal' of our list of nested subsequences. <br/><br/> <center><img src="/assets/img/compact2.png" width="600" height="auto"/></center> <br/><br/> (For example, in the above picture our sequence $(g_n')$ begins with $g_1$, $g_3$, $g_9$, $\ldots$.) <br/><br/> To see that this works, fix some $i \in \mathbb{N}$. Then if we take the sequence $(g_n'(y_i))$ and remove the first $i - 1$ terms, the resulting sequence is a subsequence of $(g_{ni}(y_i))$, which is convergent by construction; so this means $(g_n'(y_i))$ is convergent as well. </div> <h2 id="step-4--concluding">Step 4 — concluding</h2> <p>Finally, we’re ready to conclude — we’ll use the fact that $(y_i)$ forms a nice sequence of representatives for $K$ (from <span class="crossref">Claim 5</span>) together with the fact that $(g_n’)$ converges pointwise at each $y_i$ (from <span class="crossref">Lemma 6</span>) to conclude that $(g_n’)$ satisfies the condition described in <span class="crossref">Claim 4</span>.</p> <div class="claim"> For every $\varepsilon &gt; 0$, there exists $N$ such that for all $m, n \geq N$ and all $y \in K$, we have \[\lvert g_m'(y) - g_n'(y)\rvert \leq \varepsilon.\] </div> <div class="proof"> First, let $c$ be a constant such that $\lVert g_n\rVert \leq c$ for all $n \in \mathbb{N}$ (such $c$ exists because $(g_n)$ is bounded). <br/><br/> Now fix $\varepsilon &gt; 0$. Then using <span class="crossref">Claim 5</span>, we can first find a constant $M$ such that for every $y \in K$, there is some $i \in \{1, \ldots, M\}$ with $\lVert y - y_i\rVert \leq \frac{\varepsilon}{4c}$; fix this value of $M$. <br/><br/> Then for each $i \in \{1, \ldots, M\}$, we know the sequence $(g_n'(y_i))$ is convergent and therefore Cauchy (by <span class="crossref">Lemma 6</span>), so there is some $N_i$ such that for all $m, n \geq N_i$ we have $\lVert g_m'(y_i) - g_n'(y_i)\rVert \leq \frac{\varepsilon}{2}$. <br/><br/> Finally, let $N = \max\{N_1, \ldots, N_M\}$. To see that this has the desired property, consider any $y \in K$, and fix $y_i$ with $i \in \{1, \ldots, M\}$ such that $\lVert y - y_i\rVert \leq \frac{\varepsilon}{4c}$. Then we can write \[\lVert g_m'(y) - g_n'(y)\rVert \leq \lVert g_m'(y) - g_m'(y_i)\rVert + \lVert g_m'(y_i) - g_n'(y_i)\rVert + \lVert g_n'(y_i) - g_n'(y)\rVert\] by the triangle inequality. (The intuition here is that we know $g_m'$ and $g_n'$ should be 'close' at $y_i$, and we know $y$ should be close to $y_i$, so we should be able to bound each of these terms.) <br/><br/> For the first term, we have \[\lVert g_m'(y) - g_m'(y_i)\rVert \leq \lVert g_m'\rVert \lVert y - y_i\rVert \leq c\cdot \frac{\varepsilon}{4c} = \frac{\varepsilon}{4}\] (the first inequality is by the definition of the operator norm of $g_m'$). We can do the same for the last term to get that it's at most $\frac{\varepsilon}{4}$ as well. Finally, for the middle term, we have \[\lVert g_m'(y_i) - g_n'(y_i)\rVert \leq \frac{\varepsilon}{2},\] since we know $m, n \geq N \geq N_i$ and we defined $N_i$ to guarantee this inequality holds. <br/><br/> Putting these together gives that \[\lVert g_m'(y) - g_n'(y)\rVert \leq \frac{\varepsilon}{4} + \frac{\varepsilon}{2} + \frac{\varepsilon}{4} = \varepsilon\] for all $m, n \geq N$ and $y \in K$, as desired. </div> <p>This concludes the proof of <span class="crossref">Theorem 1</span> — we’ve started with an arbitrary bounded sequence $(g_n) \subseteq Y^*$ and obtained a subsequence $(g_n’) \subseteq (g_n)$ satisfying the condition of <span class="crossref">Claim 4</span> (using <span class="crossref">Claim 5</span> to choose a nice set of representatives, <span class="crossref">Lemma 6</span> to find a subsequence converging pointwise at each representative, and finally using the triangle inequality to get the conclusion, as stated in <span class="crossref">Claim 7</span>), which by <span class="crossref">Claim 4</span> means that the sequence $(T^\ast g_n’)$ is convergent.</p>]]></content><author><name></name></author><category term="analysis,"/><category term="functional-analysis"/><summary type="html"><![CDATA[A proof of the theorem from functional analysis that the adjoint of a compact linear operator between Banach spaces is also compact.]]></summary></entry><entry><title type="html">Perfect Power Polynomials</title><link href="https://sanjanad1024.github.io/blog/2022/powerpoly/" rel="alternate" type="text/html" title="Perfect Power Polynomials"/><published>2022-06-04T00:00:00+00:00</published><updated>2022-06-04T00:00:00+00:00</updated><id>https://sanjanad1024.github.io/blog/2022/powerpoly</id><content type="html" xml:base="https://sanjanad1024.github.io/blog/2022/powerpoly/"><![CDATA[<p>(This post is based on a talk I gave at my high school’s math club.)</p> <h1 id="introduction">Introduction</h1> <p>In this post, we’ll answer the following question.</p> <div class="question"> Which integer-coefficient polynomials $P$ have the property that $P(n)$ is a perfect power for every integer $n$? </div> <p>To be more precise, we’ll use the following definitions. (Some notational conventions: we use $\mathbb{Z}[x]$ and $\mathbb{Q}[x]$ to denote the sets of polynomials with integer coefficients and rational coefficients, respectively, and we use $\nu_p(n)$ to denote the greatest power of $p$ dividing $n$.)</p> <div class="definition"> We say an integer $n$ is a <em>perfect power</em> if $n = m^k$ for integers $m$ and $k$ with $k &gt; 1$. </div> <div class="definition"> We say a polynomial $P \in \mathbb{Z}[x]$ is a <em>perfect power</em> if $P(x) = Q(x)^k$ for some polynomial $Q(x) \in \mathbb{Z}[x]$ and some integer $k &gt; 1$. </div> <p>If a polynomial $P$ is a perfect power, then $P(n)$ is a perfect power for every integer $n$ — we can write $P(n)$ as $Q(n)^k$. So it’s natural to ask whether the converse is true — if we know that $P(n)$ is a perfect power for every integer $n$, then must $P$ <em>itself</em> be a perfect power? It turns out the answer is yes.</p> <div class="theorem"> If a polynomial $P \in \mathbb{Z}[x]$ has the property that $P(n)$ is a perfect power for all integers $n$, then $P$ itself must be a perfect power. </div> <p>In this post, we’ll explain some theory regarding the behavior of integer-coefficient polynomials, and use that theory to prove this statement.</p> <h2 id="proof-idea">Proof Idea</h2> <p>First we’ll give a high-level overview of the proof. We’ll start by factoring our polynomial $P$ as \[P(x) = c\cdot Q_1(x)^{e_1}\cdot Q_2(x)^{e_2}\cdots Q_k(x)^{e_k}\] for some distinct irreducible polynomials $Q_i(x) \in \mathbb{Z}[x]$ and some integer $c$. (Unique factorization <em>does</em> hold in $\mathbb{Z}[x]$, but if you are uncomfortable with this, then you can perform the factorization in $\mathbb{Q}[x]$ and clear denominators, allowing $c$ to be rational — this doesn’t affect the proof at all.)</p> <p>The main idea of the proof is to construct distinct primes $p_1$, $p_2$, $\ldots$, $p_k$ and some integer $n$, such that for each $i$, we have $\nu_{p_i}(Q_i(n)) = 1$ and $\nu_{p_i}(Q_j(n)) = 0$ for $j \neq i$ — we’re constructing one prime $p_i$ for each factor $Q_i$, and trying to use these primes to ‘pull out’ the exponents $e_i$. (We also want our primes $p_i$ to not divide $c$.) If we can do so, then we have $\nu_{p_i}(P(n)) = e_i$ for each $i$. Since $P(n)$ is the $d$th power of an integer for some $d &gt; 1$, then we must have $\gcd(e_1, \ldots, e_k) = d$, and therefore we can conclude that $P$ is the $d$th power of a polynomial.</p> <p>We’ll now see some facts about integer-coefficient polynomials that allow us to find such primes $p_1$, $\ldots$, $p_k$.</p> <h1 id="bounded-gcds">Bounded GCDs</h1> <p>In this section, we’ll prove the following lemma.</p> <div class="lemma"> Let $P, Q \in \mathbb{Z}[x]$ be two relatively prime polynomials. Then there is some constant $c$ such that $\gcd(P(n), Q(n)) \leq c$ for all integers $n$. </div> <p>In order to prove this, we can use the Euclidean Algorithm.</p> <h2 id="euclidean-algorithm-for-polynomials">Euclidean Algorithm for Polynomials</h2> <p>If we’re trying to find the gcd of two <em>integers</em> $a$ and $b$, we know that $\gcd(a, b) = \gcd(a - kb, b)$ for any integer $k$. So then we can repeatedly replace the larger number with its remainder mod the smaller number until we end up with $\gcd(0, d) = d$ for some nonzero integer $d$. For example, \[\gcd(20, 14) = \gcd(6, 14) = \gcd(6, 2) = \gcd(0, 2) = 2.\]</p> <p>We can do the same thing with polynomials with <em>rational</em> coefficients — given any two polynomials with rational coefficients, in order to find their gcd (the gcd of two rational-coefficient polynomials is defined as the highest-degree monic polynomial (also with rational coefficients) which divides both of them in $\mathbb{Q}[x]$), we can repeatedly replace the higher-degree one with its remainder mod the lower-degree one, until we end up with $\gcd(0, R) = R$ for some polynomial $R \in \mathbb{Q}[x]$. (The reason we’re using <em>rational</em> coefficients rather than integer coefficients here is because we can’t necessarily do polynomial division in $\mathbb{Z}[x]$ — if we’re dividing by a non-monic polynomial, we may introduce fractions.)</p> <div class="example"> Find $\gcd(x^3 + 3x + 1, x^2 - 2)$. </div> <div class="proof"> First, we can use polynomial division to get \[x^3 + 3x + 1 = (x^2 - 2)x + 5x + 1,\] which means \[\gcd(x^3 + 3x + 1, x^2 - 2) = \gcd(5x + 1, x^2 - 2).\] Now we can perform polynomial division again to get \[x^2 - 2 = (5x + 1)(\tfrac{1}{5}x - \tfrac{1}{25}) - \tfrac{49}{25}.\] So we have \[\gcd(5x + 1, x^2 - 2) = \gcd(5x + 1, \tfrac{49}{25}) = \gcd(0, \tfrac{49}{25}) = 1.\] </div> <p>This process successfully terminates (meaning that we can make one term $0$) for the same reason that it does in the integers — every step decreases the degree of our polynomials.</p> <p>Similarly to the case of integers, every polynomial we write down in this process is a linear combination of $P$ and $Q$ (where the coefficients are rational-coefficient polynomials). In the integer case, this gives us Bezout’s Theorem; similarly, here this means \[\gcd(P, Q) = A\cdot P + B\cdot Q\] for some rational-coefficient polynomials $A$ and $B$.</p> <h2 id="proving-the-lemma">Proving the Lemma</h2> <p>Now this gives us the tools to prove our lemma that relatively prime polynomials have bounded gcds.</p> <div class="proof"> Since $P$ and $Q$ are relatively prime, we have $\gcd(P, Q) = 1$, which means \[1 = A\cdot P + B\cdot Q\] for rational-coefficient polynomials $A$ and $B$. This means \[d = A^*\cdot P + B^* \cdot Q\] for <em>integer</em>-coefficient polynomials $A^*$ and $B^*$, by clearing denominators. So then $\gcd(P(n), Q(n))$ must divide $d$, for all integers $n$. </div> <h1 id="schurs-theorem">Schur’s Theorem</h1> <p>Earlier, we wrote our polynomial as \[P(x) = c\cdot Q_1(x)^{e_1}\cdot Q_2(x)^{e_2}\cdots Q_k(x)^{e_k},\] and we hoped to find primes $p_1$, $p_2$, $\ldots$, $p_k$ such that each $p_i$ functions as a sort of indicator for $Q_i(n)$ — we want $p_i$ to divide $Q_i(n)$, but not $Q_j(n)$ for any $j \neq i$.</p> <p>Since all the $Q_i$ are relatively prime as polynomials, we know that their pairwise gcds are all bounded. So if we choose our primes to be large enough, then if $p_i$ divides $Q_i(n)$ it <em>definitely</em> can’t divide $Q_j(n)$ for any other $j$.</p> <p>But what if we <em>can’t</em> choose a large enough prime — what if all primes which divided $Q_i(n)$ (over all $n$) were less than $100$, for instance? This is where Schur’s Theorem comes in.</p> <div class="theorem" text="Schur&apos;s Theorem"> If $P \in \mathbb{Z}[x]$ is a nonconstant polynomial, then there are infinitely many primes which divide $P(n)$ for some integer $n$. </div> <div class="proof"> Assume for contradiction that the only primes dividing $P(n)$, over all $n$, are $p_1$, $p_2$, $\ldots$, $p_r$. Now the idea is to construct a bunch of values of $n$ which have the same value of $P(n)$, by imposing conditions mod powers of these primes. <br/><br/> Fix some $a$ for which $P(a) \neq 0$, and for each prime $p_i$, let $\nu_{p_i}(P(a)) = e_i$. Then construct \[n \equiv a \pmod{p_i^{e_i + 1}}\] for all $i$ (this is possible by the Chinese Remainder Theorem). Then we have \[P(n) \equiv P(a) \pmod{p_i^{e_i + 1}}\] for all $i$ as well, which means \[\nu_{p_i}(P(n)) = \nu_{p_i}(P(a))\] for all $i$. But since these are the only primes which can divide either $P(n)$ or $P(a)$, this means we must have $|P(n)| = |P(a)|$. <br/><br/> So then there is some value which $P$ takes infinitely many times &mdash; namely, either $P(a)$ or $-P(a)$ &mdash; which means $P$ must be constant. </div> <p>So by Schur’s Theorem, we know that we can find arbitrarily large (and distinct) primes $p_1$, $p_2$, $\ldots$, $p_k$, and positive integers $n_1$, $n_2$, $\ldots$, $n_k$, such that $p_i \mid Q_i(n_i)$ for each $i$. We can then combine these $n_i$ into one $n$ by choosing \[n \equiv n_i \pmod{p_i}\] for all $i$ (which is possible by the Chinese Remainder Theorem). Then by the fact that gcds are bounded, we know that $p_i$ doesn’t divide $Q_j(n)$ for any $j \neq i$.</p> <h1 id="hensels-lemma">Hensel’s Lemma</h1> <p>We’ve <em>almost</em> constructed everything we wanted to — we now have our indicator primes, and we’ve shown that they aren’t affected by any factor except the one they’re assigned to. But there’s one thing missing. It’s not enough to know that $p_i \mid Q_i(n)$ — we need to know that <em>exactly one</em> power of $p_i$ divides $Q_i(n)$, or in other words, $\nu_{p_i}(Q_i(n)) = 1$. (This is so that we can get that the power of $p_i$ in the prime factorization of $P(n)$ is exactly $e_i$.)</p> <p>So we want to try actually choosing the $n_i$ mod $p_i^2$ such that $Q_i(n_i)$ is divisible by $p_i$, but not $p_i^2$. In order to do this, we’ll use Hensel’s Lemma:</p> <div class="theorem" desc="Hensel&apos;s Lemma"> Let $P \in \mathbb{Z}[x]$ be a polynomial, and $p$ a prime and $n_1$ an integer. If $p \nmid P'(n_1)$, then for any positive integer $e$ and any $c \equiv P(n_1) \pmod{p}$, we can find some $n_e \equiv n_1 \pmod{p}$ such that \[P(n_e) \equiv c \pmod{p^e}.\] </div> <p>So essentially, Hensel’s Lemma states that if we can solve a polynomial equation mod $p$, and at that point the <em>derivative</em> isn’t divisible by $p$, then we can solve it mod any power of $p$.</p> <p>Before we see the proof, we’ll first look at a specific example:</p> <div class="example"> Show that if $p &gt; 2$ and there exists $n_1$ such that $n_1^2 + 2 \equiv 0 \pmod{p}$, then for every integer $a$, there exists $n \equiv n_1 \pmod{p}$ such that $n^2 + 2 \equiv ap \pmod{p^2}$. </div> <div class="proof"> Let $n = n_1 + pt$, for some integer $t$. Then we have \[n^2 + 2 = n_1^2 + 2pn_1t + p^2t^2 + 2 \equiv n_1^2 + 2 + 2pn_1t \pmod{p^2}.\] We know $n_1^2 + 2$ is some multiple of $p$, and since $p \nmid 2n_1$, then $2pn_1t$ must run over all possible multiples of $p$. So as $t$ varies, $n^2 + 2$ must cover all multiples of $p$ mod $p^2$. </div> <p>The proof in the general case is essentially the same:</p> <div class="proof" text="Proof of Hensel&apos;s Lemma"> Induct on $e$ &mdash; in the base case $e = 1$, there is nothing to prove. Now choose $n_{e - 1} \equiv n_1 \pmod{p}$ such that $P(n_{e - 1}) \equiv c \pmod{p^{e - 1}}$, using the inductive hypothesis. Now let $n_e = n_{e - 1} + p^{e - 1}t$ for any integer $t$. <br/><br/> Let $P(x) = a_nx^n + a_{n - 1}x^{n - 1} + \cdots + a_1x + a_0$. Then we have \[(n_{e - 1} + p^{e - 1}t)^i \equiv n_{e - 1}^i + ip^{e - 1}tn_{e - 1}^{i - 1} \pmod{p^e}\] by the Binomial Theorem (every other term is divisible by $p^e$, since $2(e - 1) \geq e$). So this means \[P(n_e) \equiv P(n_{e - 1}) + p^{e - 1}\cdot P'(n_{e - 1})t \pmod{p^e}.\] Since $P'(n_{e - 1})$ is not divisible by $p$, then the second term must cover all multiples of $p^{e - 1}$ mod $p^e$, which means over all values of $t$, we must be able to get $P(n_e) \equiv c \pmod{p^e}$. </div> <p>Now in our case, we know $Q_i$ and $Q_i’$ are relatively prime, as polynomials (since the $Q_i$ are irreducible), so their gcds are again bounded. So as long as we chose our primes $p_i$ to be large enough, we know that if $p_i \mid Q_i(n_i)$, then $p_i \nmid Q_i’(n_i)$. So we can actually choose $n_i$ mod $p_i^2$ such that $Q_i(n_i) \equiv p_i \pmod{p_i^2}$.</p> <p>Then, by the Chinese Remainder Theorem we can again choose $n$ such that $n \equiv n_i \pmod{p_i^2}$ for all $i$. So for this choice of $n$, we have $\nu_{p_i}(Q_i(n)) = 1$ for all $i$.</p> <h1 id="conclusion">Conclusion</h1> <p>We’ve written \[P(x) = cQ_1(x)^{e_1}Q_2(x)^{e_2}\cdots Q_k(x)^{e_k}\] for irreducible polynomials $Q_i$, and chosen huge distinct primes $p_1$, $p_2$, $\ldots$, $p_k$ and a positive integer $n$ such that $\nu_{p_i}(Q_i(n)) = 1$ and $\nu_{p_i}(Q_j(n)) = 0$ for all $j \neq i$.</p> <p>This means for each $i$, we have \[\nu_{p_i}(P(n)) = e_i.\] But we know $P(n)$ is a $d$th power of an integer for some $d &gt; 1$. So $d$ must divide $e_i$ for all $i$. Finally, then $Q_1(n)^{e_1}\cdots Q_k(n)^{e_k}$ is a $d$th power, so $c$ must be a $d$th power as well.</p> <p>So $P$ is a $d$th power of a polynomial, and is therefore a perfect power.</p>]]></content><author><name></name></author><category term="number-theory"/><category term="olympiad"/><summary type="html"><![CDATA[Which integer-coefficient polynomials only attain values which are perfect powers?]]></summary></entry><entry><title type="html">Tournament of Towns</title><link href="https://sanjanad1024.github.io/blog/2022/tournament-of-towns/" rel="alternate" type="text/html" title="Tournament of Towns"/><published>2022-02-14T00:00:00+00:00</published><updated>2022-02-14T00:00:00+00:00</updated><id>https://sanjanad1024.github.io/blog/2022/tournament-of-towns</id><content type="html" xml:base="https://sanjanad1024.github.io/blog/2022/tournament-of-towns/"><![CDATA[<p>This winter, I looked at several problems from the <a href="https://www.turgor.ru/en/problems/">Tournament of Towns</a>; here are some that I especially liked. (The last two are among my favorite problems of all time.)</p> <div class="problem" text="ToT Fall 2009 S-A4"> Let $[n]!$ denote the product $1 \times 11 \times 111 \times \cdots \times (11\cdots 1)$ (where the last term has $n$ digits). Prove that $[n + m]!$ is divisible by $[n]!\times[m]!$. </div> <div class="sd-hidden" desc="Solution"> We have $[n]! = \frac{10 - 1}{9} \cdot \frac{10^2 - 1}{9} \cdots \frac{10^n - 1}{9}$, so it suffices to show \[\prod_{i = 1}^n (10^i - 1) \cdot \prod_{i = 1}^m (10^i - 1) \mid \prod_{i = 1}^{m + n} (10^i - 1).\] We'll show that for all primes $p$, the $\nu_p$ of the RHS is at least $\nu_p$ of the LHS. <br/><br/> Suppose $p$ is relatively prime to $10$ (otherwise $p$ cannot divide either side), and let $d = \operatorname{ord}_p 10$. Then only the terms with $i \mid d$ are relevant. If $ad$ and $bd$ are the greatest multiples of $d$ at most $n$ and $m$, respectively, then $(a + b)d \leq n + m$, so it suffices to show \[\sum_{i = 1}^a \nu_p(10^{id} - 1) + \sum_{i = 1}^b \nu_p(10^{id} - 1) \leq \sum_{i = 1}^{a + b} \nu_p(10^{id} - 1).\] But we have \[\nu_p(10^{id} - 1) = \nu_p(10^d - 1) + \nu_p(id) = \nu_p(10^d - 1) + \nu_p(i)\] by LTE. So it suffices to show \[\sum_{i = 1}^a \nu_p(i) + \sum_{i = 1}^b \nu_p(i) \leq \sum_{i = 1}^{a + b} \nu_p(i),\] which is true as $\binom{a + b}{a}$ is an integer. </div> <div class="problem" text="ToT Fall 2011 S-A6"> Prove that for $n \geq 2$, the integer \[1^1 + 3^3 + 5^5 + \cdots + (2^n - 1)^{2^n - 1}\] is a multiple of $2^n$ but not a multiple of $2^{n + 1}$. </div> <div class="sd-hidden" desc="Solution"> Induct on $n$. In the base case $n = 2$, $1^1 + 3^3 = 28$ is a multiple of $4$ but not $8$. <br/><br/> Now suppose $n \geq 3$ and assume this is true for $n - 1$, so \[1^1 + 3^3 + \cdots + (2^{n - 1} - 1)^{2^{n - 1} - 1} \equiv 2^{n - 1} \pmod{2^n}.\] Now note that for all odd $x$, we have \[\nu_2(x^{2^{n - 1}} - 1) = \nu_2(x^2 - 1) + \nu_2(2^{n - 2}) \geq n + 1,\] so then $x^{2^{n - 1}}$ is always $1$ mod $2^{n + 1}$. So then \[(x + 2^{n - 1})^{x + 2^{n - 1}} \equiv (x + 2^{n - 1})^x \equiv x^x + x^x \cdot 2^{n - 1},\] since $2(n - 1) \geq n + 1$. So this means \[1^1 + 3^3 + \cdots + (2^n - 1)^{2^n - 1} \equiv (2 + 2^{n - 1})(1^1 + 3^3 + \cdots + (2^{n - 1} - 1)^{2^{n - 1} - 1}) \pmod{2^{n + 1}}.\] But $2 + 2^{n - 1}$ is even, and the second sum is $2^{n - 1}$ mod $2^n$ by the induction hypothesis, so then the original sum is $2^n$ mod $2^{n + 1}$, as desired. </div> <div class="sd-hidden" desc="Comments"> It makes sense to induct because the sum is pretty intractable on its own, but when you lift from $2^n$ to $2^{n + 1}$, a lot of the terms are either the same or closely related. </div> <div class="problem" text="ToT Fall 2019 S-A7"> Some of the integers $1$, $2$, $\ldots$, $n$ have been colored red so that for each triplet of red numbers $a$, $b$, $c$ (not necessarily distinct), if $a(b - c)$ is a multiple of $n$ then $b = c$. Prove that there are no more than $\varphi(n)$ red numbers. </div> <div class="sd-hidden" desc="Solution"> Let $p_1 &lt; p_2 &lt; \cdots &lt; p_r$ be the primes dividing $n$ which divide some red number, and $q_1$, $q_2$, $\ldots$, $q_s$ the primes dividing $n$ which don't divide any red number. If $r = 0$ then all red numbers are relatively prime to $n$ so there are at most $\varphi(n)$ red numbers; now assume $r \geq 1$. <div class="claim-un"> There are at most $\frac{n}{p_r} \cdot \prod \frac{q_i - 1}{q_i}$ red numbers. </div> <div class="proof"> Let $n = p_r\cdot m$, so $m$ is divisible by each of the $q_i$. Then each residue class mod $m$ contains at most one red number (if $b \equiv c \pmod{m}$, then take $a$ to be a red multiple of $p_r$, so $a(b - c)$ is a multiple of $n$). Additionally, all red numbers are relatively prime to each $q_i$, so all red residues mod $m$ are relatively prime to each $q_i$ as well. So then there are at most $m \prod \frac{q_i - 1}{q_i}$ red numbers. </div> But we have \[\varphi(n) = n \cdot \prod_{i = 1}^r \frac{p_i - 1}{p_i} \cdot \prod_{i = 1}^s \frac{q_i - 1}{q_i}.\] We have the bound \[\prod_{i = 1}^r \frac{p_i - 1}{p_i} \geq \prod_{i = 2}^{p_i} \frac{i - 1}{i} = \frac{1}{p_i},\] so then our bound on the count of red numbers is at most $\varphi(n)$. </div> <div class="sd-hidden" desc="Comments"> You can start by trying small cases &mdash; here the small case is when we only have one prime dividing $n$ with a red multiple, since having none gives exactly $\varphi(n)$. If we look at which residues are allowed then we get exactly $\frac{n}{p}\prod \frac{q - 1}{q}$. Then if we try to go to a more general case, we realize that there <em>isn't</em> really a much better bound we can get (at least, not one that I could find), so we probably still have to use this bound &mdash; and then thinking about size a bit finishes. </div> <div class="problem" text="ToT Spring 2009 S-A7"> Initially, the number $6$ is written on a blackboard. On the $n$th step (for $n \geq 1$), if the number $k$ is on the blackboard, it is replaced with $k + \gcd(k, n)$. Prove that at each step, the number on the blackboard increases either by $1$ or by a prime number. </div> <div class="sd-hidden" desc="Solution"> The first step is $6 \to 7$, the second step is $7 \to 8$, and the third step is $8 \to 9$. <div class="claim-un"> Suppose that after step $n$, the number on the blackboard is $3n$. Then if the number next increases by more than $1$ on step $m$, it increases by a prime and becomes $3m$. </div> <div class="proof"> We have that $m$ is the smallest integer greater than $n$ for which \[\gcd(m, 3n + m - n - 1) = \gcd(m, 2n - 1) &gt; 1.\] But if $p$ is any prime dividing $2n - 1$, then $n \equiv \frac{p + 1}{2} \pmod{p}$, so the smallest $m &gt; n$ with $p \mid m$ is \[m = n + \frac{p - 1}{2}.\] So then the first $m$ for which the gcd is not $1$ is $m = n + \frac{p - 1}{2}$ where $p$ is the smallest prime dividing $2n - 1$, and here the gcd is \[\gcd(2n + p - 1, 2n - 1) = p.\] So step $m$ is \[3n + \frac{p - 1}{2} - 1 \to 3n + \frac{p - 1}{2} - 1 + p = 3m,\] as desired. </div> Since after step $3$ the number is $3\cdot 3$, by induction this means all additions are $1$ or prime, and each prime addition results in $3m$ on the board after turn $m$. </div> <div class="sd-hidden" desc="Comments"> I think this is a pretty rigid problem &mdash; the idea is to try out the process for small values of $n$, and then you notice that there's a pattern: every nontrivial jump ends up in a position $(n, 3n)$, which is surprising but turns out to be not that hard to prove. Maybe it is even expected that the sequence should have some nice property like this, because if there's no good relationship between $n$ and $k$, the problem seems pretty intractable. But even without that heuristic, doing small cases is a good idea. </div> <div class="problem" text="ToT Spring 2011 S-A6"> In every cell of a square table is a number. The sum of the largest two numbers in each row is $a$ and the sum of the largest two numbers in each column is $b$. Prove that $a = b$. </div> <div class="sd-hidden" desc="Solution"> Assume not, so WLOG $a &lt; b$. Label the rows and columns $1$ through $n$. Draw a graph on $n$ vertices and for each column, draw an edge between the row numbers with the two greatest elements of that column (breaking ties arbitrarily) &mdash; multiple edges between two vertices are allowed. <br/><br/> This graph has $n$ vertices and $n$ edges, so it must contain a cycle $(r_1r_2\cdots r_k)$, possibly of length $2$. Suppose edge $r_ir_{i + 1}$ corresponds to column $c_i$. Then if $x(r, c)$ denotes the entry in $(r, c)$, we have \[\sum x(r_i, c_i) + x(r_{i + 1}, c_i) = bn\] by looking at columns. But \[\sum x(r_i, c_{i - 1}) + x(r_i, c_i) \leq an\] by looking at rows (since each term is at most the sum of the two largest numbers in each row). But these are the same sum, so $bn \leq an$, contradiction as $a &lt; b$. </div> <div class="sd-hidden" desc="Comments"> I think this is an arrows problem &mdash; the idea is that you draw a vertical line for each column connecting the two largest numbers in that column, and then you can get a cycle by adding in horizontal lines, which are at most the largest numbers in the rows. <br/><br/> <center><img src="/assets/img/11ttssa6-arrows.png" width="250" height="auto"/></center> </div> <div class="problem" text="ToT Spring 2016 S-A4"> There are $64$ towns in a country, and some pairs of towns are connected by roads but we don't know these pairs. We may choose any pair of towns and find out whether they are connected by a road. Our aim is to determine whether it is possible to travel between any two towns using roads. Prove that there is no algorithm which would enable us to do this in less than $2016$ questions. </div> <div class="sd-hidden" desc="Solution"> Call the person answering us the <em>oracle</em>; we'll show that the oracle can ensure that at every step until the end, the current knowledge is compatible with both the graph being connected and not. <br/><br/> Color an edge red if the oracle answers no, and blue if yes. Define a <em>blob</em> to be a set of vertices $S$ such that all edges in $S$ are drawn, and the blue edges form exactly a tree. Call a position <em>great</em> if it is a collection of blobs (possibly with size 1) so that there are no blue edges between distinct blobs. <br/><br/> Then the oracle can preserve greatness: suppose the position is great, and we query $uv$ with $u$ in blob $S$ and $v$ in blob $T$. The oracle answers no unless every other edge between blobs $S$ and $T$ has been queried (and colored red), in which case he answers yes. <br/><br/> This preserves greatness, as an answer of yes merges the blobs into a bigger blob. The graph will end up connected, but in the last turn there were two blobs, and if the oracle had answered no instead then the graph would be disconnected. So this works. </div> <div class="sd-hidden" desc="Comments"> This is essentially the strategy of saying yes unless forced to say no &mdash; if you have a connected blue subgraph and the other edges between vertices in that subgraph have not been colored red, then you don't ever have to query those edges. Any strategy that preserves greatness and ends with the graph connected should work; in particular saying no unless that would disconnect the graph works as well. </div> <div class="problem" text="ToT Spring 2021 J-A7"> Let $p$ and $q$ be two coprime positive integers. A frog hops along the number line such that on each hop, it moves either $p$ units to the right or $q$ units to the left. Eventually, the frog returns to the initial point. Prove that for every positive integer $d &lt; p + q$, there are two numbers visited by the frog which differ by $d$. </div> <div class="sd-hidden" desc="Solution"> Write the list of jumps $+p$ and $-q$ made by the frog in a circle, so there are $kq$ points on the circle labelled $+p$ and $kp$ points labelled $-q$, in some order. Then it suffices to show that there is some subset of consecutive points on this circle whose sum of labels is exactly $d$. <br/><br/> By Bezout's Theorem there are positive integers $a$ and $b$ with $d = ap - bq$. Look at subsets of exactly $a + b$ consecutive points on the circle. Then it suffices to show there is a subset with at most $a$ points labelled $+p$, and a subset with at least $a$ points labelled $+p$ &mdash; as we walk around the circle (taking the subset starting at each point), the number of points $+p$ in the subset changes by $0$ or $\pm 1$ each step, so by Discrete IVT there then must exist a subset with exactly $a$ points $+p$. <br/><br/> First assume for contradiction that all subsets have at least $a + 1$ points labelled $+p$. Then sum over all $k(p + q)$ subsets. Each point is counted in $a + b$ subsets, and there are exactly $kq$ points $+p$, so then \[k(p + q)(a + 1) \leq kq(a + b).\] This implies $ap - bq \leq -p - q$, contradiction. Similarly, if all subsets have at most $a - 1$ points $+p$, then \[k(p + q)(a - 1) \geq kq(a + b),\] which implies $ap - bq \geq p + q$, contradiction. <br/><br/> So then there exists a subset with at most $a$ points $+p$, and a subset with at least $a$ points $+p$, so by Discrete IVT there exists one with exactly $a$ points $+p$, and this subset sums to exactly $d$. </div> <div class="sd-hidden" desc="Comments"> I really like this problem; I think it's a cool combination of local (look at a frame and shift it) and global (sum over all frames) ideas. I think the main realization is that you want to write the jumps in a circle and look at a <em>fixed</em> set of counts (meaning a specific pair of $a$ and $b$) &mdash; you can sort of motivate this by the fact that you want to look at <em>something</em>, and keeping track of multiple possible solutions would be hard as these seem pretty unrelated to each other (and there sometimes is only one). </div> <div class="problem" text="ToT Spring 2019 S-A7"> Consider lattice paths of finite length which start from $(0, 0)$ and move only up and right, which we call <em>skeletons</em>. For each skeleton, we define a <em>worm</em> consisting of all unit cells in the plane sharing at least one point with the skeleton. (For example, for the path from $(0, 0)$ to $(1, 0)$, the corresponding worm has six cells). Prove that for every integer $n &gt; 2$, the number of worms which can be tiled by dominoes in exactly $n$ ways is equal to $\varphi(n)$. </div> <div class="sd-hidden" desc="Solution"> First, we're going to find a way to recurse the number of tilings of a worm. <br/><br/> Note that the number of ways to tile the worm of skeleton $(0, 0)$ is $2$, since it is a $2 \times 2$ grid. Also, define the number of ways to tile the worm of the empty skeleton as $1$. <br/><br/> Define the <em>twisty part</em> of a skeleton $S$ to be the maximal sequence of points starting with the end for which the skeleton alternates direction, and define the <em>head</em> of a skeleton to be the remainder not in the twisty part (the head may be empty). Here are some examples, with the heads in red and the twisty parts in blue. <br/><br/> <center><img src="/assets/img/19ttssa7-twistypart.png" width="400" height="auto"/></center> <div class="claim-un"> To get the number of ways to tile skeleton $S$, we add the number of ways to tile the skeleton with the last point removed, and the number of ways to tile the head of $S$. </div> <div class="proof"> WLOG the last move in the skeleton is vertical. Now if we place a horizontal domino at the top-right corner, the remaining worm is the worm of the skeleton where we delete the last point of $S$. <br/><br/> <center><img src="/assets/img/19ttssa7-recurse1.png" width="250" height="auto"/></center> Meanwhile, if we place a vertical domino in the top-right corner, then this forces the positions of a bunch of other dominoes. Placing all these other dominoes has the effect of removing the entire twisty part, leaving us with the worm of the head of $S$. <br/><br/> <center><img src="/assets/img/19ttssa7-recurse2.png" width="250" height="auto"/></center> So then the total number of ways to tile $S$ is the sum of these two new skeletons, the one with the last point deleted and the head. </div> Now we can make a big tree, where the top entry is the skeleton $(0, 0)$, and when we go down, left means adding a step right while right means adding a step up. At each node, we write the number of ways to tile that skeleton. We also write the two entries we summed according to the previous claim &mdash; if this was a left child, then we write the skeleton with the last element removed on the left and the head on the right, while if this was a right child then we do the opposite. <br/><br/> <center><img src="/assets/img/19ttssa7-tree.png" width="600" height="auto"/></center> We claim this becomes the Euclidean Algorithm tree where $(a, b)$ has descendants $(a + b, a)$ and $(b, a + b)$. <br/><br/> To show this, if $(a, b)$ with skeleton $S$ is a left child, then $a$ is the number of ways for $S$ with its last point removed, and $b$ is the number of ways for the head of $S$. <br/><br/> Then if we go left one step to get skeleton $T$, then $S$ with $a + b$ ways is $T$ with its last point removed, and $S$ with its last point removed is the head of $T$ (since the twisty part is only the last two points), which gives $(a + b, a)$. <br/><br/> Meanwhile, if we go one step right to get skeleton $T$, then $S$ is still $T$ with its last point removed, but the head of $S$ is the head of $T$ (since we went left to get to $S$, and then right to get to $T$, so $T$ swallows the twisty part of $S$), which gives us $(b, a + b)$. <br/><br/> Similar things happen when $S$ is a right child, which proves that our tree is the Euclidean Algorithm tree. But it's clear that every pair $(a, b)$ with $\gcd(a, b) = 1$ occurs exactly once in this tree (since we can trace it back to $(1, 1)$ uniquely), and no pairs with $\gcd(a, b) &gt; 1$ are in this tree. So then the number of occurrences of $n$ in this tree are the number of ways to write $n = a + b$ with $\gcd(a, b) = 1$, which is $\varphi(n)$. </div> <div class="sd-hidden" desc="Comments"> This is one of my favorite problems of all time. It's a rigid problem &mdash; the point is to start by trying to figure out how to count the number of tilings of a given worm. You can try placing the tile at the end and drawing the dominoes that are forced, and you notice that you end up with a smaller skeleton with a nice characterization. Once you get the recursion you can try drawing a tree to perform the recursion for small worms, and eventually you notice that this is very similar to the Euclidean Algorithm tree &mdash; and you can do the tracking in such a way that it actually <em>becomes</em> the Euclidean Algorithm tree. </div>]]></content><author><name></name></author><category term="olympiad"/><summary type="html"><![CDATA[Some cool problems from the Tournament of Towns.]]></summary></entry></feed>